{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e26bbd67",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01050e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO       The following preferences have been changed for Brian2GeNN, reset them manually if you use a different device later in the same script: codegen.loop_invariant_optimisations, core.network.default_schedule [brian2.devices.genn]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import brian2 as b2\n",
    "from brian2 import *\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from dataset_util import Synthetic_Dataset_Utils\n",
    "\n",
    "\n",
    "import brian2genn\n",
    "\n",
    "\n",
    "\n",
    "set_device('genn', use_GPU=True)\n",
    "\n",
    "\n",
    "msec_step = 100\n",
    "shared_clock = Clock(dt=msec_step*ms)\n",
    "\n",
    "\n",
    "set_device('genn', use_GPU=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ecf38",
   "metadata": {},
   "source": [
    "# Adex neuron dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8db2a487-6d56-497a-97e5-90c207c9b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make weights always non-negative!\n",
    "\n",
    "\n",
    "# Equations for everything. I_post in the synapse is modifying I in the target neuron\n",
    "\n",
    "\n",
    "# Parameters for neurons\n",
    "Cm = 281 * pF  # Membrane capacitance\n",
    "gL = 30 * nS   # Leak conductance\n",
    "EL = -70.6 * mV  # Leak reversal potential\n",
    "Vth = -50.4 * mV  # Spike threshold\n",
    "\n",
    "DeltaT = 2 * mV  # Slope factor\n",
    "Vr = -70.6 * mV  # Reset potential\n",
    "\n",
    "Vcut = -40 * mV  # Cutoff potential for spike generation\n",
    "tau_A = 1 * ms  # Adaptation time constant\n",
    "c = 4 * nS       # Coupling parameter\n",
    "b = 0.0805 * nA  # Spike-triggered adaptation increment\n",
    "\n",
    "# Parameters for synapses\n",
    "tau_rise = 5 * ms  # Rise time constant for AMPA\n",
    "tau_decay = 50 * ms  # Decay time constant for NMDA\n",
    "w_init = 0.5 * nS   # Initial synaptic weight (conductance)\n",
    "\n",
    "# AdEx neuron equations\n",
    "eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + Iexc + Iinh - A ) / Cm : volt\n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "dX/dt = -X / tau_decay + Y / tau_rise : volt   # Spike trace\n",
    "dY/dt = -Y / tau_decay : volt  # Glutamate decay\n",
    "Iexc : amp \n",
    "Iinh : amp \n",
    "batch_sum_X : 1  # Accumulate X values over a batch\n",
    "running_sum_X : 1  # Sum of X during a stimulus\n",
    "'''\n",
    "# Ii = I + input_stimuli(t)  :  amp  # Input current\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72633ba",
   "metadata": {},
   "source": [
    "# Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47062c2",
   "metadata": {},
   "source": [
    "### *original equations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8be1709",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + I - A ) / Cm : volt\n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "dX/dt = -X / tau_decay + Y / tau_rise : volt   # Spike trace\n",
    "dY/dt = -Y / tau_decay : volt  # Glutamate decay\n",
    "I = input_stimuli(t, indices) : amp\n",
    "indices : integer \n",
    "'''\n",
    "\n",
    "out_eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + I_tot - A ) / Cm : volt\n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "dX/dt = -X / tau_decay + Y / tau_rise : volt   # Spike trace\n",
    "dY/dt = -Y / tau_decay : volt  # Glutamate decay\n",
    "Iexc : amp # Synaptic input \n",
    "Iexc2 : amp # Synaptic input \n",
    "I_tot = Iexc + Iexc2 + output_stimuli(t, indices) : amp\n",
    "indices : integer  # dimensionless index variable\n",
    "'''\n",
    "\n",
    "# Synapse equations (Spike trace dynamics)\n",
    "\n",
    "\n",
    "syn_eqs_exc = '''\n",
    "w : siemens  # Synaptic weight (conductance)\n",
    "Iexc_post = w * X_pre : amp (summed)\n",
    "'''\n",
    "\n",
    "syn_eqs_exc_output = '''\n",
    "w : siemens  # Synaptic weight (conductance)\n",
    "Iexc2_post = w * X_pre : amp (summed)\n",
    "'''\n",
    "\n",
    "syn_eqs_inh= '''\n",
    "w : siemens  # Synaptic weight (conductance)\n",
    "Iinh_post = w * X_pre : amp (summed)\n",
    "'''\n",
    "\n",
    "def update_batch_sum(synapses):\n",
    "    synapses.batch_sum_X += synapses.X  # Perform the operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6b0256-5f89-4305-aabc-db9a2f407551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a476e92-55dc-46e9-96ce-b1e49df3c533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e081c6e0-620c-49da-902e-1b81fcd03207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0841870f-7d0d-4f54-ab84-6443a64b0771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make weights always non-negative!\n",
    "\n",
    "\n",
    "# Equations for everything. I_post in the synapse is modifying I in the target neuron\n",
    "\n",
    "\n",
    "# Parameters for neurons\n",
    "Cm = 281 * pF  # Membrane capacitance\n",
    "gL = 30 * nS   # Leak conductance\n",
    "EL = -70.6 * mV  # Leak reversal potential\n",
    "Vth = -50.4 * mV  # Spike threshold\n",
    "\n",
    "DeltaT = 2 * mV  # Slope factor\n",
    "Vr = -70.6 * mV  # Reset potential\n",
    "\n",
    "Vcut = -40 * mV  # Cutoff potential for spike generation\n",
    "tau_A = 1 * ms  # Adaptation time constant\n",
    "c = 4 * nS       # Coupling parameter\n",
    "b = 0.0805 * nA  # Spike-triggered adaptation increment\n",
    "\n",
    "# Parameters for synapses\n",
    "tau_rise = 5 * ms  # Rise time constant for AMPA\n",
    "tau_decay = 50 * ms  # Decay time constant for NMDA\n",
    "w_init = 0.5 * nS   # Initial synaptic weight (conductance)\n",
    "\n",
    "\n",
    "\n",
    "eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + Iexc + Iinh - A ) / Cm : volt \n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "dX/dt = -X / tau_decay + Y / tau_rise : volt   # Spike trace\n",
    "dY/dt = -Y / tau_decay : volt  # Glutamate decay \n",
    "Iexc : amp\n",
    "Iinh : amp\n",
    "batch_sum_X : 1   # Accumulate X values over a batch\n",
    "running_sum_X : 1  # Sum of X during a stimulus\n",
    "'''\n",
    "\n",
    "input_eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + I - A ) / Cm : volt \n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp \n",
    "dX/dt = -X / tau_decay + Y / tau_rise : volt   # Spike trace\n",
    "dY/dt = -Y / tau_decay : volt  # Glutamate decay\n",
    "I = input_stimuli(t, indices) : amp\n",
    "indices : integer\n",
    "'''\n",
    "\n",
    "out_eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT)\n",
    "          + Iexc + Iexc2 + output_stimuli(t, indices) - A ) / Cm : volt\n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "dX/dt = -X / tau_decay + Y / tau_rise : volt    # Spike trace\n",
    "dY/dt = -Y / tau_decay : volt  # Glutamate decay\n",
    "Iexc : amp  # Synaptic input\n",
    "Iexc2 : amp # Synaptic input\n",
    "indices : integer\n",
    "'''\n",
    "\n",
    "syn_eqs_exc = '''\n",
    "w : siemens   # Synaptic weight, conductance\n",
    "Iexc_post += w * X_pre : amp (summed)\n",
    "'''\n",
    "\n",
    "exc_output = '''\n",
    "w : siemens   # Synaptic weight, conductance\n",
    "Iexc2_post += w * X_pre : amp (summed)\n",
    "'''\n",
    "\n",
    "syn_eqs_inh = '''\n",
    "w : siemens   # Synaptic weight, conductance\n",
    "Iinh_post += w * X_pre : amp (summed)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad255e-817b-41ba-a1d7-9d5e6aaaca92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f74789c-4606-4006-ae2d-8560f955bc70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a1308-8396-4056-ab13-e2e7a5c998af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7185e68b-ef00-496d-8f53-9d6df7360111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12543d7e",
   "metadata": {},
   "source": [
    "### *STDP*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fdfec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stdp parameters\n",
    "sigma = 0.3                                                                                                                                                                                                             \n",
    "taupre = 5*ms\n",
    "taupost = 8*ms\n",
    "wmax = 1.2\n",
    "wmin = -0.5\n",
    "Apre = 0.4*sigma\n",
    "Apost = -0.2*sigma\n",
    "\n",
    "#characteristics of neurons\n",
    "tau = tau_A\n",
    "vr = Vr\n",
    "vt = 1.5*mV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a23c1f5",
   "metadata": {},
   "source": [
    "### *Hebbian*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcbf0bd",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b185fd",
   "metadata": {},
   "source": [
    "### Creating network architecture and connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4cda873-deff-49bb-87b2-c6f1a89fea8f",
   "metadata": {
    "id": "e4cda873-deff-49bb-87b2-c6f1a89fea8f"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gist_dim = 16\n",
    "\n",
    "\n",
    "def make_groups(dims, eqs = eqs, with_input = False):\n",
    "    \"\"\"\n",
    "    Just a function to make neurongroups of specified dimension. Assigns input equations (which read the input timedarray, hopefully) \n",
    "    to the first group if with_input = True\n",
    "    \"\"\"\n",
    "\n",
    "    groups = []\n",
    "\n",
    "    for i, dim in enumerate(dims):\n",
    "    \n",
    "        if i == 0 and with_input == True:\n",
    "    \n",
    "            groups.append(NeuronGroup(dim, input_eqs, threshold='v > Vcut', reset='v = Vr', method='euler'))\n",
    "    \n",
    "        else:\n",
    "    \n",
    "            groups.append(NeuronGroup(dim, eqs, threshold='v > Vcut', reset='v = Vr', method='euler'))\n",
    "    \n",
    "    for group in groups:\n",
    "        \n",
    "        group.v = EL\n",
    "    \n",
    "    \n",
    "    return groups\n",
    "\n",
    "def make_bottom_up_connections(R, E_0, E_1, syn_eqs_exc, syn_eqs_inh):\n",
    "\n",
    "\n",
    "  S_p = Synapses(R, E_0, model=syn_eqs_exc,\n",
    "        on_pre='Y_post = 1*volt ')\n",
    "\n",
    "    \n",
    "  S_p.connect(condition='i == j')  # One-to-one connections\n",
    "  S_p.w = 'w_init'\n",
    "\n",
    "\n",
    "  S_m = Synapses(R, E_1, model=syn_eqs_inh,\n",
    "        on_pre='Y_post = 1*volt')\n",
    "  S_m.connect(condition='i == j')  # One-to-one connections\n",
    "  S_m.w = 'w_init'\n",
    "\n",
    "  return S_p, S_m\n",
    "def make_top_down_connections(R, E_0, E_1, syn_eqs_exc, syn_eqs_inh):\n",
    "\n",
    "\n",
    "  S_p = Synapses(R, E_1, model=syn_eqs_exc,\n",
    "        on_pre='Y_post = 1*volt')\n",
    "  S_p.connect()\n",
    "  S_p.w = 'rand() * w_init'\n",
    "\n",
    "\n",
    "  S_m = Synapses(R, E_0, model=syn_eqs_inh,\n",
    "        on_pre='Y_post = 1*volt')\n",
    "  S_m.connect()\n",
    "  S_m.w = 'rand() * w_init'\n",
    "\n",
    "\n",
    "  return S_p, S_m\n",
    "\n",
    "def make_gist_connections(Rs, G):\n",
    "\n",
    "  S = Synapses(Rs[0], G, model=syn_eqs_exc,\n",
    "        on_pre='Y_post = 1*volt')\n",
    "  S.connect(p=0.05)  # Connect with 5% probability\n",
    "  S.w = 'rand() * w_init'   # This is slightly different from the paper: it should be based on a ratio\n",
    "\n",
    "  S_gist_input = S\n",
    "\n",
    "  for R in Rs[1:]:\n",
    "    S = Synapses(G, R, model=syn_eqs_exc,\n",
    "        on_pre='Y_post = 1*volt')\n",
    "    S.connect(p=0.05)  # Connect with 5% probability\n",
    "    S_gist_output = S\n",
    "\n",
    "  return S_gist_input, S_gist_output\n",
    "# num_classes_per_layer and max_depth depend on the same parameters used when generating the datset\n",
    "\n",
    "\n",
    "def make_output_layer(num_classes_per_layer, max_depth, w_out_init = None ):\n",
    "\n",
    "    if w_out_init == None:\n",
    "        w_out_init = w_init/10\n",
    "        \n",
    "        \n",
    "\n",
    "    total_neurons = sum([num_classes_per_layer**(d+1) for d in range(max_depth)])\n",
    "    \n",
    "    \n",
    "    Os = NeuronGroup(N=total_neurons, model = out_eqs, threshold='v > Vcut', reset='v = Vr', method='euler')\n",
    "\n",
    "    \n",
    "\n",
    "    S_o = Synapses(Os, Os, model=syn_eqs_exc_output, on_pre='Y_post = 1*volt')\n",
    "    \n",
    "    trace = 0\n",
    "    for d in range(num_classes_per_layer - 1):\n",
    "\n",
    "        new_trace = trace + num_classes_per_layer**(d+1)\n",
    "        \n",
    "        source_indices = list(range(trace, trace + num_classes_per_layer**(d+1)))\n",
    "        target_indices = list(range(new_trace , new_trace + num_classes_per_layer**(d+2)))\n",
    "\n",
    "        ii, jj = np.meshgrid(source_indices, target_indices, indexing='ij')\n",
    "        \n",
    "        S_o.connect(i=ii.flatten(), j=jj.flatten())\n",
    "\n",
    "        trace = new_trace\n",
    "\n",
    "\n",
    "    stimulus_indices = []\n",
    "\n",
    "    for i, n in enumerate([num_classes_per_layer**i for i in range(1, max_depth+1)]):\n",
    "        for _ in range(n):\n",
    "            stimulus_indices.append(int(i))\n",
    "            \n",
    "    Os.indices = stimulus_indices \n",
    "\n",
    "\n",
    "    return Os, S_o\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b21bf6e",
   "metadata": {},
   "source": [
    "### Main function compiling network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0HO2o7eGvf0C",
   "metadata": {
    "id": "0HO2o7eGvf0C"
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_network(dims, syn_eqs_exc, syn_eqs_inh, num_classes_per_layer, max_depth, w_out_init = None ):\n",
    "\n",
    "    max_depth += 1\n",
    "    \n",
    "    Rs = make_groups(dims, with_input = True)\n",
    "    Es_0 = make_groups(dims[:-1])\n",
    "    Es_1 = make_groups(dims[:-1])\n",
    "    G = NeuronGroup(gist_dim, eqs, threshold='v > Vcut', reset='v = Vr', method='euler')\n",
    "    \n",
    "    Os, S_o_internal = make_output_layer(num_classes_per_layer, max_depth) # Hopefully this is correct\n",
    "    \n",
    "    connections = {}\n",
    "    connections[\"output_internal\"] = S_o_internal\n",
    "    \n",
    "    for i in range(len(Rs)-1):\n",
    "    \n",
    "    \n",
    "        S_p, S_m = make_bottom_up_connections(Rs[i], Es_0[i], Es_1[i], syn_eqs_exc, syn_eqs_inh)\n",
    "        \n",
    "        connections[f\"bottom_up_{i}\"] = [S_p, S_m]\n",
    "    \n",
    "        if i != len(Rs)-1:\n",
    "        \n",
    "            S_p, S_m = make_top_down_connections(Rs[i+1], Es_0[i], Es_1[i], syn_eqs_exc, syn_eqs_inh)\n",
    "            \n",
    "            connections[f\"top_down_{i}\"] = [S_p, S_m]\n",
    "        \n",
    "    S_gist_input, S_gist_output = make_gist_connections(Rs, G)\n",
    "    \n",
    "    connections[\"gist_input\"] = S_gist_input\n",
    "    connections[\"gist_output\"] = S_gist_output\n",
    "    \n",
    "    '''\n",
    "    S_o_external = Synapses(Rs[-1], Os, model=syn_eqs_exc,\n",
    "        on_pre='Y_post = 1*volt')\n",
    "    S_o_external.connect()\n",
    "    S_o_external.w = 'rand() * w_init'\n",
    "    '''\n",
    "    S_o_external = []\n",
    "    for O in Os:\n",
    "        S = Synapses(Rs[-1], O, model=syn_eqs_exc, on_pre='Y_post = 1*volt')\n",
    "        S.connect()\n",
    "        S.w = 'rand() * w_init'\n",
    "        S_o_external.append(S)\n",
    "    connections[\"output_external\"] = S_o_external\n",
    "\n",
    "\n",
    "    return Rs, Es_0, Es_1, G, S_gist_input, S_gist_output, Os, S_o_external, connections\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fab0d6-5862-442a-8f30-a43f29742762",
   "metadata": {},
   "source": [
    "### prepping input for network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef16053a-1a23-4a21-9099-2f384c0d0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing input\n",
    "\n",
    "def normalize_tensor(tensor, old_min, old_max, new_min, new_max):\n",
    "\n",
    "    normalized_tensor = (tensor - old_min) / (old_max - old_min)\n",
    "\n",
    "\n",
    "    scaled_tensor = normalized_tensor * (new_max - new_min) + new_min\n",
    "\n",
    "    return scaled_tensor\n",
    "\n",
    "\n",
    "#split key (label of the curve/graph which is the input) and curve\n",
    "\n",
    "def normalize_and_unwrap_dataset(dt, minval,maxval):\n",
    "\n",
    "\n",
    "    minimum = 0\n",
    "    maximum = 0\n",
    "    \n",
    "    all_curves = [torch.tensor(curve, dtype = torch.float64) for curve in chain.from_iterable(dt[\"curves\"].values())]\n",
    "    \n",
    "    for curve in all_curves:\n",
    "    \n",
    "        _min = torch.min(curve)\n",
    "        _max = torch.max(curve)\n",
    "        if(minimum > _min): minimum = _min\n",
    "        if(maximum < _max): maximum = _max\n",
    "\n",
    "\n",
    "    unwrapped = []\n",
    "    for key in dt[\"categories\"].keys():\n",
    "        for curve in dt[\"curves\"][key]:\n",
    "            unwrapped.append((torch.tensor(key), normalize_tensor(torch.tensor(curve), minimum, maximum, minval, maxval)))\n",
    "            \n",
    "    return unwrapped\n",
    "            \n",
    "def get_output_stimuli_indexes_from_labels(labels, num_classes_per_layer):\n",
    "\n",
    "    if labels.ndim == 1:\n",
    "        labels = labels.unsqueeze(0)  # Convert to 2D with shape (1, len(I_indexes))\n",
    "\n",
    "    indexes = torch.zeros_like(labels)\n",
    "    \n",
    "    for i in range(0, labels.shape[1]):\n",
    "    \n",
    "        summed = 0\n",
    "        if i>0:\n",
    "            summed = torch.stack([labels[:,j]*num_classes_per_layer**(i-j) for j in range(i)]).sum(dim=0)\n",
    "    \n",
    "        indexes[:,i] = summed + labels[:,i] # These are more intelligible, since they indicate which neuron to stimulate for each level of granularity\n",
    "\n",
    "    # But we need to adapt them for a situation where all neurons are concatenated in a single list\n",
    "    \n",
    "    to_sum = 0\n",
    "    for i in range(0, labels.shape[1]):\n",
    "\n",
    "        if i>0:\n",
    "            to_sum += num_classes_per_layer**i \n",
    "\n",
    "        indexes[:,i] = indexes[:,i] + to_sum\n",
    "\n",
    "    return indexes\n",
    "\n",
    "\n",
    "\n",
    "def get_output_current_arrays(I_indexes, dim, I_value):\n",
    "    # Ensure I_indexes is 2D for consistent processing\n",
    "    if I_indexes.ndim == 1:\n",
    "        I_indexes = I_indexes.unsqueeze(0)  # Convert to 2D with shape (1, len(I_indexes))\n",
    "\n",
    "    # Create an output tensor of zeros\n",
    "    out = torch.zeros((I_indexes.shape[0], dim), dtype=torch.float32)\n",
    "\n",
    "    # Row indices (batch indices) for advanced indexing\n",
    "    row_indices = torch.arange(I_indexes.shape[0]).repeat_interleave(I_indexes.shape[1])\n",
    "\n",
    "    # Flattened column indices (curve indexes)\n",
    "    col_indices = I_indexes.flatten()\n",
    "\n",
    "    # Set the values using advanced indexing\n",
    "    out[row_indices, col_indices] = I_value\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class CurveDataset(Dataset):\n",
    "    def __init__(self, data, minval, maxval):\n",
    "        \n",
    "        self.data = normalize_and_unwrap_dataset(data, minval, maxval)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        labels, curves = self.data[idx]\n",
    "      \n",
    "  \n",
    "        return labels, curves.flatten()\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn(batch, msec_step, num_pause_blocks, num_classes_per_layer, out_dim):\n",
    "\n",
    "    \n",
    "\n",
    "    labels, curves = zip(*batch)\n",
    "\n",
    "    labels = torch.stack(labels, dim=0)\n",
    "    curves = torch.stack(curves, dim=0)\n",
    "\n",
    "\n",
    "   \n",
    "    pause = torch.zeros_like(curves[0])  \n",
    "    \n",
    "    pause_block = torch.tile(pause, (num_pause_blocks, 1))  \n",
    "    \n",
    "    # Interleave stimulus rows with the pause block\n",
    "    curves_with_pause = torch.vstack([torch.vstack((row, pause_block)) for row in curves])\n",
    "\n",
    "    visual_stimulus = TimedArray(curves_with_pause.numpy() * nA, dt=msec_step*ms)\n",
    "\n",
    "\n",
    "    stimulus_indexes = TimedArray(np.tile([1] +\n",
    "                                     [0] * num_pause_blocks, curves.size(0)), dt=msec_step*ms)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    out_stimuli_idx = get_output_stimuli_indexes_from_labels(labels, num_classes_per_layer)\n",
    "   \n",
    "    out_stimuli_array = get_output_current_arrays(out_stimuli_idx, out_dim, 1)\n",
    "\n",
    "    label_pause = torch.zeros(out_dim)  \n",
    "    \n",
    "    label_pause_block = torch.tile(label_pause, (num_pause_blocks, 1)) \n",
    "\n",
    "    out_stimuli_with_pause = torch.vstack([torch.vstack((row, label_pause_block)) for row in out_stimuli_array])\n",
    "\n",
    "    output_stimuli = TimedArray(out_stimuli_with_pause.numpy() * nA, dt=msec_step*ms) \n",
    "    \n",
    "\n",
    " \n",
    "    \n",
    "\n",
    "    return stimulus_indexes, output_stimuli , visual_stimulus, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558f904c",
   "metadata": {},
   "source": [
    "# Main script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db54a67",
   "metadata": {},
   "source": [
    "### settings for network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fa69c0b-f02f-4d63-b488-40bc7758c46a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'syn_eqs_exc_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Es layers:    Error layers\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#S_o_external: connecting last RS with output layer\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Os:            output layer\u001b[39;00m\n\u001b[0;32m      5\u001b[0m dims \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m Rs, Es_0, Es_1, G, S_gist_input, S_gist_output, Os, S_o_external, connections \u001b[38;5;241m=\u001b[39m \u001b[43mmake_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msyn_eqs_exc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msyn_eqs_inh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes_per_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m Rs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mindices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(Rs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mN)\n",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m, in \u001b[0;36mmake_network\u001b[1;34m(dims, syn_eqs_exc, syn_eqs_inh, num_classes_per_layer, max_depth, w_out_init)\u001b[0m\n\u001b[0;32m      7\u001b[0m Es_1 \u001b[38;5;241m=\u001b[39m make_groups(dims[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      8\u001b[0m G \u001b[38;5;241m=\u001b[39m NeuronGroup(gist_dim, eqs, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv > Vcut\u001b[39m\u001b[38;5;124m'\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv = Vr\u001b[39m\u001b[38;5;124m'\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuler\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m Os, S_o_internal \u001b[38;5;241m=\u001b[39m \u001b[43mmake_output_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes_per_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Hopefully this is correct\u001b[39;00m\n\u001b[0;32m     12\u001b[0m connections \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     13\u001b[0m connections[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_internal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m S_o_internal\n",
      "Cell \u001b[1;32mIn[4], line 96\u001b[0m, in \u001b[0;36mmake_output_layer\u001b[1;34m(num_classes_per_layer, max_depth, w_out_init)\u001b[0m\n\u001b[0;32m     89\u001b[0m total_neurons \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([num_classes_per_layer\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(d\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_depth)])\n\u001b[0;32m     92\u001b[0m Os \u001b[38;5;241m=\u001b[39m NeuronGroup(N\u001b[38;5;241m=\u001b[39mtotal_neurons, model \u001b[38;5;241m=\u001b[39m out_eqs, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv > Vcut\u001b[39m\u001b[38;5;124m'\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv = Vr\u001b[39m\u001b[38;5;124m'\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuler\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 96\u001b[0m S_o \u001b[38;5;241m=\u001b[39m Synapses(Os, Os, model\u001b[38;5;241m=\u001b[39m\u001b[43msyn_eqs_exc_output\u001b[49m, on_pre\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY_post = 1*volt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     98\u001b[0m trace \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_classes_per_layer \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'syn_eqs_exc_output' is not defined"
     ]
    }
   ],
   "source": [
    "#Es layers:    Error layers\n",
    "#S_o_external: connecting last RS with output layer\n",
    "#Os:            output layer\n",
    "\n",
    "dims = [10, 6,6,3]\n",
    "Rs, Es_0, Es_1, G, S_gist_input, S_gist_output, Os, S_o_external, connections = make_network(dims, syn_eqs_exc, syn_eqs_inh, num_classes_per_layer=3, max_depth=3)\n",
    "\n",
    "\n",
    "Rs[0].indices = range(Rs[0].N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db21657",
   "metadata": {},
   "source": [
    "data set import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e07d4a-7015-4980-824b-6c82bfaef728",
   "metadata": {},
   "outputs": [],
   "source": [
    "su = Synthetic_Dataset_Utils()\n",
    "\n",
    "ranges = [30,30,30,30]  # Ranges for each parameter\n",
    "\n",
    "prior_params = [10,10,10,10]  # Initial parameters\n",
    "\n",
    "num_samples_per_class=5\n",
    "N=15\n",
    "\n",
    "# Build the tree\n",
    "max_depth = 3 # Adjust as needed\n",
    "num_classes_per_layer = 3  # Adjust as needed\n",
    "\n",
    "std_multiplier = 1\n",
    "\n",
    "tree = su.build_tree(prior_params, 0, max_depth, num_classes_per_layer, std_multiplier, ranges)\n",
    "\n",
    "synth_dataset = su.make_dataset(tree, num_samples_per_class=num_samples_per_class, N=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92dc886",
   "metadata": {},
   "source": [
    "### settings and loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4fa470-20a2-424b-b831-eae2887e6576",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = sum([len(o) for o in Os])\n",
    "\n",
    "lr = 0.03\n",
    "msec_step = 500\n",
    "batch_size = 20\n",
    "num_pause_blocks = 1\n",
    "\n",
    "dataset = CurveDataset(synth_dataset, 0.6, 1.5)\n",
    "dl = DataLoader( dataset, shuffle = True, batch_size = batch_size, collate_fn = partial(collate_fn, msec_step=msec_step, num_pause_blocks=num_pause_blocks,\n",
    "                                                                                num_classes_per_layer = num_classes_per_layer, out_dim = output_dim) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfccbdb3",
   "metadata": {},
   "source": [
    "### functions for updating while running the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ace3fd-57b0-4fbd-8f3e-e8c741a6c1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update logic\n",
    "@network_operation()\n",
    "def add_inputs():\n",
    "    stimulus_indexes = _stimulus_indexes \n",
    "    output_stimuli = _output_stimuli\n",
    "    input_stimuli = _input_stimuli\n",
    "\n",
    "@network_operation()\n",
    "def debug():\n",
    "    print(\"Rs[0].I: \", Rs[0].I[:])\n",
    "   \n",
    "@network_operation()\n",
    "def update_sums():\n",
    "\n",
    "    current_idx = int(defaultclock.t / msec_step*ms)\n",
    "    \n",
    "    if stimulus_indexes.values[current_idx] == 1:\n",
    "\n",
    "        \n",
    "        for n in range(len(Rs)-1):\n",
    "\n",
    "            if n > 0:\n",
    "                Rs[n+1].batch_sum_X += Rs[n+1].X_\n",
    "                \n",
    "            Es_0[n].batch_sum_X += Es_0[n].X_\n",
    "            Es_1[n].batch_sum_X += Es_1[n].X_\n",
    "\n",
    "#function to train network by inputting the same input into the output layers\n",
    "@network_operation()\n",
    "def apply_weight_update():\n",
    "    \n",
    "    print(\"Applying weight update\")\n",
    "    \n",
    "    for n in range(len(Rs)-1):\n",
    "\n",
    "        print(\"n: \", n)\n",
    "        \n",
    "        for i in range(len(Rs[n+1])):\n",
    "            for j in range(len(Es_0[n])):\n",
    "   \n",
    "            \n",
    "                S_p, S_m = connections[f\"top_down_{n}\"]\n",
    "    \n",
    "                S_p.w[i,j] += lr * Es_0[n].batch_sum_X[j] * Rs[n+1].batch_sum_X[i] * siemens\n",
    "                \n",
    "                S_m.w[i,j] += lr * Es_1[n].batch_sum_X[j] * Rs[n+1].batch_sum_X[i]  * siemens\n",
    "            \n",
    "                Rs[n+1].batch_sum_X[i] = 0\n",
    "                \n",
    "                Es_0[n].batch_sum_X[i]= 0\n",
    "    \n",
    "                Es_1[n].batch_sum_X[i] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eaabfc",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a739de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables to extract from data set\n",
    "stimulus_indexes, output_stimuli, input_stimuli, labels = next(iter(dl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95ed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_scope()\n",
    "\n",
    "monitor = StateMonitor(Rs[0], ['v', 'I'], record=[0]) #membrane volage of first neuron group\n",
    "spike_monitor_input = SpikeMonitor(Rs[0]) #spikes from input neurons\n",
    "spike_monitor_output = SpikeMonitor(Rs[3]) #spikes from output neurons\n",
    "\n",
    "net = Network(Rs, Es_0, Es_1, G,  Os, connections, monitor, spike_monitor_input, spike_monitor_output, add_inputs, debug, update_sums, apply_weight_update)\n",
    "\n",
    "lable_list = []\n",
    "\n",
    "for i, (_stimulus_indexes, _output_stimuli, _input_stimuli, labels) in enumerate(dl):\n",
    "    #print(labels)\n",
    "    print(f\"batch n.{i}\")\n",
    "    lable_list.append(labels)\n",
    "\n",
    "    net.run((batch_size + batch_size*num_pause_blocks) * 100 * ms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the network\n",
    "\n",
    "#variables to save\n",
    "\n",
    "save_data = {\n",
    "    'Rs': [group.get_states() for group in Rs],  # Save neuron group states\n",
    "    'connections': [conn.get_states(['w']) for conn in connections],  # Save synaptic weights\n",
    "    'Es_0': Es_0.get_states(),  # Save state monitors\n",
    "    'Es_1': Es_1.get_states(),\n",
    "    'parameters': {\n",
    "        'gL': gL,\n",
    "        'EL': EL,\n",
    "        'DeltaT': DeltaT,\n",
    "        'Cm': Cm,\n",
    "    },  # Add other parameters as needed\n",
    "}\n",
    "\n",
    "# Save to a file\n",
    "with open('trained_network.pkl', 'wb') as f:\n",
    "    pickle.dumps(save_data, f)\n",
    "\n",
    "print(\"Network saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d844991c",
   "metadata": {},
   "source": [
    "laod the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273c08b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from the file\n",
    "with open('trained_network.pkl', 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "# Extract components\n",
    "Rs = loaded_data['Rs']\n",
    "Es_0 = loaded_data['Es_0']\n",
    "Es_1 = loaded_data['Es_1']\n",
    "G = loaded_data['G']\n",
    "Os = loaded_data['Os']\n",
    "connections = loaded_data['connections']\n",
    "monitor = loaded_data['monitor']\n",
    "spike_monitor_input = loaded_data['spike_monitor_input']\n",
    "spike_monitor_output = loaded_data['spike_monitor_output']\n",
    "\n",
    "# Rebuild the network\n",
    "net = Network(Rs, Es_0, Es_1, G, Os, connections, monitor, spike_monitor_input, spike_monitor_output)\n",
    "print(\"Network loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c6ae9f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1231699",
   "metadata": {},
   "source": [
    "### Decoding the class from the spike trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cc9e130-68f9-4344-9b90-2b7c73282fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd4dc77",
   "metadata": {},
   "source": [
    "# visualizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b3455c",
   "metadata": {},
   "source": [
    "### accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38519c2",
   "metadata": {},
   "source": [
    "### granuality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cc7de56-20b5-4998-a35a-86e86f301bcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spike_monitor_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pprint(\u001b[38;5;28mvars\u001b[39m(\u001b[43mspike_monitor_input\u001b[49m))\n\u001b[0;32m      2\u001b[0m pprint(\u001b[38;5;28mvars\u001b[39m(spike_monitor_output))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spike_monitor_input' is not defined"
     ]
    }
   ],
   "source": [
    "pprint(vars(spike_monitor_input))\n",
    "pprint(vars(spike_monitor_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "002d5551-26cc-4093-88ac-28068d6dec9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spike_monitor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Firing rate plot\u001b[39;00m\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(\u001b[43mspike_monitor\u001b[49m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m/\u001b[39m ms, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime (ms)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpike Count\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spike_monitor' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0UAAAFlCAYAAAAktEOqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdNUlEQVR4nO3dfWzdVf3A8U/b0VuItAzn2m0WJyggTxturBYkBFNpIhnuD0MdZlsWHkQnARqVjYdVRNepQJZIcWGA+A9uSIQYthSwshilZmFbE4jbCM65hdhuU2ln0Za1398fhvqr62C36wPdeb2S+0cP59zvueQwePO9vbcgy7IsAAAAElU43hsAAAAYT6IIAABImigCAACSJooAAICkiSIAACBpoggAAEiaKAIAAJImigAAgKSJIgAAIGmiCAAASFreUfTb3/425s+fH9OnT4+CgoJ49tln33fN5s2b49Of/nTkcrn4xCc+EU888cQwtgoAADDy8o6i7u7umDVrVjQ1NR3T/D//+c9x9dVXx5VXXhltbW1x2223xQ033BDPP/983psFAAAYaQVZlmXDXlxQEM8880wsWLDgqHPuuOOO2LhxY7z22msDY1/+8pfjrbfeiubm5uFeGgAAYERMGu0LtLa2Rk1NzaCx2trauO222466pqenJ3p6egZ+7u/vj7///e/x4Q9/OAoKCkZrqwAAwAdclmVx6NChmD59ehQWjsxHJIx6FLW3t0d5efmgsfLy8ujq6op//etfcfLJJx+xprGxMe69997R3hoAADBB7du3Lz760Y+OyHONehQNx4oVK6K+vn7g587OzjjjjDNi3759UVpaOo47AwAAxlNXV1dUVlbGqaeeOmLPOepRVFFRER0dHYPGOjo6orS0dMi7RBERuVwucrncEeOlpaWiCAAAGNFfqxn17ymqrq6OlpaWQWMvvvhiVFdXj/alAQAA3lfeUfTPf/4z2traoq2tLSL+85HbbW1tsXfv3oj4z1vfFi9ePDD/5ptvjt27d8e3v/3t2LlzZzz88MPx1FNPxe233z4yrwAAAOA45B1Fr7zySlx88cVx8cUXR0REfX19XHzxxbFy5cqIiPjrX/86EEgRER//+Mdj48aN8eKLL8asWbPigQceiEcffTRqa2tH6CUAAAAM33F9T9FY6erqirKysujs7PQ7RQAAkLDRaINR/50iAACADzJRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRtWFDU1NcXMmTOjpKQkqqqqYsuWLe85f82aNXHOOefEySefHJWVlXH77bfHv//972FtGAAAYCTlHUUbNmyI+vr6aGhoiG3btsWsWbOitrY29u/fP+T8J598MpYvXx4NDQ2xY8eOeOyxx2LDhg1x5513HvfmAQAAjlfeUfTggw/GjTfeGEuXLo3zzjsv1q5dG6eccko8/vjjQ85/+eWX47LLLovrrrsuZs6cGVdddVUsXLjwfe8uAQAAjIW8oqi3tze2bt0aNTU1/32CwsKoqamJ1tbWIddceumlsXXr1oEI2r17d2zatCm+8IUvHPU6PT090dXVNegBAAAwGiblM/ngwYPR19cX5eXlg8bLy8tj586dQ6657rrr4uDBg/HZz342siyLw4cPx8033/yeb59rbGyMe++9N5+tAQAADMuof/rc5s2bY9WqVfHwww/Htm3b4pe//GVs3Lgx7rvvvqOuWbFiRXR2dg489u3bN9rbBAAAEpXXnaIpU6ZEUVFRdHR0DBrv6OiIioqKIdfcc889sWjRorjhhhsiIuLCCy+M7u7uuOmmm+Kuu+6KwsIjuyyXy0Uul8tnawAAAMOS152i4uLimDNnTrS0tAyM9ff3R0tLS1RXVw+55u233z4ifIqKiiIiIsuyfPcLAAAwovK6UxQRUV9fH0uWLIm5c+fGvHnzYs2aNdHd3R1Lly6NiIjFixfHjBkzorGxMSIi5s+fHw8++GBcfPHFUVVVFW+88Ubcc889MX/+/IE4AgAAGC95R1FdXV0cOHAgVq5cGe3t7TF79uxobm4e+PCFvXv3DrozdPfdd0dBQUHcfffd8eabb8ZHPvKRmD9/fnz/+98fuVcBAAAwTAXZBHgPW1dXV5SVlUVnZ2eUlpaO93YAAIBxMhptMOqfPgcAAPBBJooAAICkiSIAACBpoggAAEiaKAIAAJImigAAgKSJIgAAIGmiCAAASJooAgAAkiaKAACApIkiAAAgaaIIAABImigCAACSJooAAICkiSIAACBpoggAAEiaKAIAAJImigAAgKSJIgAAIGmiCAAASJooAgAAkiaKAACApIkiAAAgaaIIAABImigCAACSJooAAICkiSIAACBpoggAAEiaKAIAAJImigAAgKSJIgAAIGmiCAAASJooAgAAkiaKAACApIkiAAAgaaIIAABImigCAACSJooAAICkiSIAACBpoggAAEiaKAIAAJImigAAgKSJIgAAIGmiCAAASJooAgAAkiaKAACApIkiAAAgaaIIAABImigCAACSJooAAICkDSuKmpqaYubMmVFSUhJVVVWxZcuW95z/1ltvxbJly2LatGmRy+Xi7LPPjk2bNg1rwwAAACNpUr4LNmzYEPX19bF27dqoqqqKNWvWRG1tbezatSumTp16xPze3t74/Oc/H1OnTo2nn346ZsyYEX/5y1/itNNOG4n9AwAAHJeCLMuyfBZUVVXFJZdcEg899FBERPT390dlZWXccsstsXz58iPmr127Nn70ox/Fzp0746STThrWJru6uqKsrCw6OzujtLR0WM8BAABMfKPRBnm9fa63tze2bt0aNTU1/32CwsKoqamJ1tbWIdf86le/iurq6li2bFmUl5fHBRdcEKtWrYq+vr6jXqenpye6uroGPQAAAEZDXlF08ODB6Ovri/Ly8kHj5eXl0d7ePuSa3bt3x9NPPx19fX2xadOmuOeee+KBBx6I733ve0e9TmNjY5SVlQ08Kisr89kmAADAMRv1T5/r7++PqVOnxiOPPBJz5syJurq6uOuuu2Lt2rVHXbNixYro7OwceOzbt2+0twkAACQqrw9amDJlShQVFUVHR8eg8Y6OjqioqBhyzbRp0+Kkk06KoqKigbFPfepT0d7eHr29vVFcXHzEmlwuF7lcLp+tAQAADEted4qKi4tjzpw50dLSMjDW398fLS0tUV1dPeSayy67LN54443o7+8fGHv99ddj2rRpQwYRAADAWMr77XP19fWxbt26+NnPfhY7duyIr33ta9Hd3R1Lly6NiIjFixfHihUrBuZ/7Wtfi7///e9x6623xuuvvx4bN26MVatWxbJly0buVQAAAAxT3t9TVFdXFwcOHIiVK1dGe3t7zJ49O5qbmwc+fGHv3r1RWPjf1qqsrIznn38+br/99rjoootixowZceutt8Ydd9wxcq8CAABgmPL+nqLx4HuKAACAiA/A9xQBAACcaEQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkbVhR1NTUFDNnzoySkpKoqqqKLVu2HNO69evXR0FBQSxYsGA4lwUAABhxeUfRhg0bor6+PhoaGmLbtm0xa9asqK2tjf3797/nuj179sQ3v/nNuPzyy4e9WQAAgJGWdxQ9+OCDceONN8bSpUvjvPPOi7Vr18Ypp5wSjz/++FHX9PX1xVe+8pW4995748wzzzyuDQMAAIykvKKot7c3tm7dGjU1Nf99gsLCqKmpidbW1qOu++53vxtTp06N66+//piu09PTE11dXYMeAAAAoyGvKDp48GD09fVFeXn5oPHy8vJob28fcs3vfve7eOyxx2LdunXHfJ3GxsYoKysbeFRWVuazTQAAgGM2qp8+d+jQoVi0aFGsW7cupkyZcszrVqxYEZ2dnQOPffv2jeIuAQCAlE3KZ/KUKVOiqKgoOjo6Bo13dHRERUXFEfP/9Kc/xZ49e2L+/PkDY/39/f+58KRJsWvXrjjrrLOOWJfL5SKXy+WzNQAAgGHJ605RcXFxzJkzJ1paWgbG+vv7o6WlJaqrq4+Yf+6558arr74abW1tA49rrrkmrrzyymhra/O2OAAAYNzldacoIqK+vj6WLFkSc+fOjXnz5sWaNWuiu7s7li5dGhERixcvjhkzZkRjY2OUlJTEBRdcMGj9aaedFhFxxDgAAMB4yDuK6urq4sCBA7Fy5cpob2+P2bNnR3Nz88CHL+zduzcKC0f1V5UAAABGTEGWZdl4b+L9dHV1RVlZWXR2dkZpael4bwcAABgno9EGbukAAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDSRBEAAJA0UQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDShhVFTU1NMXPmzCgpKYmqqqrYsmXLUeeuW7cuLr/88pg8eXJMnjw5ampq3nM+AADAWMo7ijZs2BD19fXR0NAQ27Zti1mzZkVtbW3s379/yPmbN2+OhQsXxksvvRStra1RWVkZV111Vbz55pvHvXkAAIDjVZBlWZbPgqqqqrjkkkvioYceioiI/v7+qKysjFtuuSWWL1/+vuv7+vpi8uTJ8dBDD8XixYuP6ZpdXV1RVlYWnZ2dUVpams92AQCAE8hotEFed4p6e3tj69atUVNT898nKCyMmpqaaG1tPabnePvtt+Odd96J008/Pb+dAgAAjIJJ+Uw+ePBg9PX1RXl5+aDx8vLy2Llz5zE9xx133BHTp08fFFb/q6enJ3p6egZ+7urqymebAAAAx2xMP31u9erVsX79+njmmWeipKTkqPMaGxujrKxs4FFZWTmGuwQAAFKSVxRNmTIlioqKoqOjY9B4R0dHVFRUvOfa+++/P1avXh0vvPBCXHTRRe85d8WKFdHZ2Tnw2LdvXz7bBAAAOGZ5RVFxcXHMmTMnWlpaBsb6+/ujpaUlqqurj7ruhz/8Ydx3333R3Nwcc+fOfd/r5HK5KC0tHfQAAAAYDXn9TlFERH19fSxZsiTmzp0b8+bNizVr1kR3d3csXbo0IiIWL14cM2bMiMbGxoiI+MEPfhArV66MJ598MmbOnBnt7e0REfGhD30oPvShD43gSwEAAMhf3lFUV1cXBw4ciJUrV0Z7e3vMnj07mpubBz58Ye/evVFY+N8bUD/5yU+it7c3vvSlLw16noaGhvjOd75zfLsHAAA4Tnl/T9F48D1FAABAxAfge4oAAABONKIIAABImigCAACSJooAAICkiSIAACBpoggAAEiaKAIAAJImigAAgKSJIgAAIGmiCAAASJooAgAAkiaKAACApIkiAAAgaaIIAABImigCAACSJooAAICkiSIAACBpoggAAEiaKAIAAJImigAAgKSJIgAAIGmiCAAASJooAgAAkiaKAACApIkiAAAgaaIIAABImigCAACSJooAAICkiSIAACBpoggAAEiaKAIAAJImigAAgKSJIgAAIGmiCAAASJooAgAAkiaKAACApIkiAAAgaaIIAABImigCAACSJooAAICkiSIAACBpoggAAEiaKAIAAJImigAAgKSJIgAAIGmiCAAASJooAgAAkiaKAACApIkiAAAgaaIIAABImigCAACSNqwoampqipkzZ0ZJSUlUVVXFli1b3nP+L37xizj33HOjpKQkLrzwwti0adOwNgsAADDS8o6iDRs2RH19fTQ0NMS2bdti1qxZUVtbG/v37x9y/ssvvxwLFy6M66+/PrZv3x4LFiyIBQsWxGuvvXbcmwcAADheBVmWZfksqKqqiksuuSQeeuihiIjo7++PysrKuOWWW2L58uVHzK+rq4vu7u547rnnBsY+85nPxOzZs2Pt2rXHdM2urq4oKyuLzs7OKC0tzWe7AADACWQ02mBSPpN7e3tj69atsWLFioGxwsLCqKmpidbW1iHXtLa2Rn19/aCx2traePbZZ496nZ6enujp6Rn4ubOzMyL+8zcAAABI17tNkOe9nfeUVxQdPHgw+vr6ory8fNB4eXl57Ny5c8g17e3tQ85vb28/6nUaGxvj3nvvPWK8srIyn+0CAAAnqL/97W9RVlY2Is+VVxSNlRUrVgy6u/TWW2/Fxz72sdi7d++IvXAYSldXV1RWVsa+ffu8VZNR5awxVpw1xoqzxljp7OyMM844I04//fQRe868omjKlClRVFQUHR0dg8Y7OjqioqJiyDUVFRV5zY+IyOVykcvljhgvKyvzDxljorS01FljTDhrjBVnjbHirDFWCgtH7tuF8nqm4uLimDNnTrS0tAyM9ff3R0tLS1RXVw+5prq6etD8iIgXX3zxqPMBAADGUt5vn6uvr48lS5bE3LlzY968ebFmzZro7u6OpUuXRkTE4sWLY8aMGdHY2BgREbfeemtcccUV8cADD8TVV18d69evj1deeSUeeeSRkX0lAAAAw5B3FNXV1cWBAwdi5cqV0d7eHrNnz47m5uaBD1PYu3fvoFtZl156aTz55JNx9913x5133hmf/OQn49lnn40LLrjgmK+Zy+WioaFhyLfUwUhy1hgrzhpjxVljrDhrjJXROGt5f08RAADAiWTkfjsJAABgAhJFAABA0kQRAACQNFEEAAAk7QMTRU1NTTFz5swoKSmJqqqq2LJly3vO/8UvfhHnnntulJSUxIUXXhibNm0ao50y0eVz1tatWxeXX355TJ48OSZPnhw1NTXvezbhXfn+ufau9evXR0FBQSxYsGB0N8gJI9+z9tZbb8WyZcti2rRpkcvl4uyzz/bvUY5JvmdtzZo1cc4558TJJ58clZWVcfvtt8e///3vMdotE9Fvf/vbmD9/fkyfPj0KCgri2Weffd81mzdvjk9/+tORy+XiE5/4RDzxxBN5X/cDEUUbNmyI+vr6aGhoiG3btsWsWbOitrY29u/fP+T8l19+ORYuXBjXX399bN++PRYsWBALFiyI1157bYx3zkST71nbvHlzLFy4MF566aVobW2NysrKuOqqq+LNN98c450z0eR71t61Z8+e+OY3vxmXX375GO2UiS7fs9bb2xuf//znY8+ePfH000/Hrl27Yt26dTFjxowx3jkTTb5n7cknn4zly5dHQ0ND7NixIx577LHYsGFD3HnnnWO8cyaS7u7umDVrVjQ1NR3T/D//+c9x9dVXx5VXXhltbW1x2223xQ033BDPP/98fhfOPgDmzZuXLVu2bODnvr6+bPr06VljY+OQ86+99trs6quvHjRWVVWVffWrXx3VfTLx5XvW/tfhw4ezU089NfvZz342WlvkBDGcs3b48OHs0ksvzR599NFsyZIl2Re/+MUx2CkTXb5n7Sc/+Ul25plnZr29vWO1RU4Q+Z61ZcuWZZ/73OcGjdXX12eXXXbZqO6TE0dEZM8888x7zvn2t7+dnX/++YPG6urqstra2ryuNe53inp7e2Pr1q1RU1MzMFZYWBg1NTXR2to65JrW1tZB8yMiamtrjzofIoZ31v7X22+/He+8806cfvrpo7VNTgDDPWvf/e53Y+rUqXH99dePxTY5AQznrP3qV7+K6urqWLZsWZSXl8cFF1wQq1atir6+vrHaNhPQcM7apZdeGlu3bh14i93u3btj06ZN8YUvfGFM9kwaRqoLJo3kpobj4MGD0dfXF+Xl5YPGy8vLY+fOnUOuaW9vH3J+e3v7qO2TiW84Z+1/3XHHHTF9+vQj/uGD/284Z+13v/tdPPbYY9HW1jYGO+REMZyztnv37vjNb34TX/nKV2LTpk3xxhtvxNe//vV45513oqGhYSy2zQQ0nLN23XXXxcGDB+Ozn/1sZFkWhw8fjptvvtnb5xhRR+uCrq6u+Ne//hUnn3zyMT3PuN8pgoli9erVsX79+njmmWeipKRkvLfDCeTQoUOxaNGiWLduXUyZMmW8t8MJrr+/P6ZOnRqPPPJIzJkzJ+rq6uKuu+6KtWvXjvfWOMFs3rw5Vq1aFQ8//HBs27YtfvnLX8bGjRvjvvvuG++twRHG/U7RlClToqioKDo6OgaNd3R0REVFxZBrKioq8poPEcM7a++6//77Y/Xq1fHrX/86LrrootHcJieAfM/an/70p9izZ0/Mnz9/YKy/vz8iIiZNmhS7du2Ks846a3Q3zYQ0nD/Xpk2bFieddFIUFRUNjH3qU5+K9vb26O3tjeLi4lHdMxPTcM7aPffcE4sWLYobbrghIiIuvPDC6O7ujptuuinuuuuuKCz0/+Y5fkfrgtLS0mO+SxTxAbhTVFxcHHPmzImWlpaBsf7+/mhpaYnq6uoh11RXVw+aHxHx4osvHnU+RAzvrEVE/PCHP4z77rsvmpubY+7cuWOxVSa4fM/aueeeG6+++mq0tbUNPK655pqBT9KprKwcy+0zgQznz7XLLrss3njjjYHwjoh4/fXXY9q0aYKIoxrOWXv77bePCJ93Y/w/v0MPx2/EuiC/z4AYHevXr89yuVz2xBNPZH/84x+zm266KTvttNOy9vb2LMuybNGiRdny5csH5v/+97/PJk2alN1///3Zjh07soaGhuykk07KXn311fF6CUwQ+Z611atXZ8XFxdnTTz+d/fWvfx14HDp0aLxeAhNEvmftf/n0OY5Vvmdt79692amnnpp94xvfyHbt2pU999xz2dSpU7Pvfe974/USmCDyPWsNDQ3Zqaeemv385z/Pdu/enb3wwgvZWWedlV177bXj9RKYAA4dOpRt37492759exYR2YMPPpht3749+8tf/pJlWZYtX748W7Ro0cD83bt3Z6ecckr2rW99K9uxY0fW1NSUFRUVZc3NzXld9wMRRVmWZT/+8Y+zM844IysuLs7mzZuX/eEPfxj4a1dccUW2ZMmSQfOfeuqp7Oyzz86Ki4uz888/P9u4ceMY75iJKp+z9rGPfSyLiCMeDQ0NY79xJpx8/1z7/0QR+cj3rL388stZVVVVlsvlsjPPPDP7/ve/nx0+fHiMd81ElM9Ze+edd7LvfOc72VlnnZWVlJRklZWV2de//vXsH//4x9hvnAnjpZdeGvK/vd49W0uWLMmuuOKKI9bMnj07Ky4uzs4888zspz/9ad7XLcgy9y8BAIB0jfvvFAEAAIwnUQQAACRNFAEAAEkTRQAAQNJEEQAAkDRRBAAAJE0UAQAASRNFAABA0kQRAACQNFEEAAAkTRQBAABJE0UAAEDS/g9g0Pg+LENQBwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "\n",
    "\n",
    "# Firing rate plot\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.hist(spike_monitor.t / ms, bins=10, alpha=0.7)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Spike Count')\n",
    "plt.title('Firing Rate of Neuron 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zkD5Zs72axi9",
   "metadata": {
    "id": "zkD5Zs72axi9"
   },
   "outputs": [],
   "source": [
    "def training_phase_1(network, dl):\n",
    "\n",
    "  for label_input, curve_input, labels in dl:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lOfMXzfIaxdn",
   "metadata": {
    "id": "lOfMXzfIaxdn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T9V1Ufi3axau",
   "metadata": {
    "id": "T9V1Ufi3axau"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Membrane potential plot\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(monitor.t / ms, monitor.v[0] / mV, label='mV')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Membrane Potential (mV)')\n",
    "plt.title('Input')\n",
    "plt.legend()\n",
    "\n",
    "# Firing rate plot\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.hist(spike_monitor.t / ms, bins=10, alpha=0.7)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Spike Count')\n",
    "plt.title('Input')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586f1b19-bab1-4990-b2ca-1aabe4ae053c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc4819-5071-4651-9378-4a9ab4117d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "network = Network(\n",
    "    *Rs,        # Unpack the list of NeuronGroups\n",
    "    *Es_0,      # Unpack the list of NeuronGroups\n",
    "    *Es_1,      # Unpack the list of NeuronGroups\n",
    "    G,          # Single NeuronGroup is fine\n",
    "    Os,         # Single NeuronGroup is fine\n",
    "    connections[\"output_internal\"],   # Single Synapses object is fine\n",
    "    connections[\"gist_input\"],        # Single Synapses object is fine\n",
    "    *connections[\"gist_output\"],      # Unpack the list of Synapses\n",
    "    *connections[\"output_external\"],  # Unpack the list of Synapses\n",
    "    spike_monitor, \n",
    "    monitor,\n",
    "    debug, \n",
    "    update_sums, \n",
    "    apply_weight_update\n",
    ")\n",
    "\n",
    "eqs_neuron = '''\n",
    "dv/dt = (-gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + I - A) / Cm : volt\n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "I = stimulus(t)  : amp  \n",
    "'''\n",
    "\n",
    "\n",
    "neuron = make_groups([1], eqs = eqs_neuron)[0]\n",
    "\n",
    "neuron\n",
    "\n",
    "# Change 2 to any value from 0.6 to 1.5, which is the range of current intensity we are probably going to use\n",
    "\n",
    "stimulus = TimedArray(np.hstack([[c] for c in np.ones(1)*0.8]) * nA, dt=10*ms)\n",
    "\n",
    "\n",
    "\n",
    "neuron.v = EL\n",
    "neuron.A = 0 * nA\n",
    "\n",
    "# Monitor the specific neuron (neuron 2)\n",
    "monitor = StateMonitor(neuron, ['v', 'I'], record=[0])\n",
    "spike_monitor = SpikeMonitor(neuron)\n",
    "\n",
    "run(1 * second)\n",
    "\n",
    "# Plot membrane potential\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Membrane potential plot\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(monitor.t / ms, monitor.v[0] / mV, label='Neuron 2 Membrane Potential')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Membrane Potential (mV)')\n",
    "plt.title('Stimulus Applied to Single Neuron')\n",
    "plt.legend()\n",
    "\n",
    "# Firing rate plot\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.hist(spike_monitor.t / ms, bins=10, alpha=0.7)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Spike Count')\n",
    "plt.title('Firing Rate of Neuron 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "0.6: 0\n",
    "0.625: 0\n",
    "0.63: 0.5\n",
    "0.65: 1.5\n",
    "0.7: 2.8\n",
    "0.8: 4.5\n",
    "1: 7.5\n",
    "1.5: 14\n",
    "2: 20\n",
    "'''\n",
    "# Let's connect 2 groups as a trial\n",
    "\n",
    "G1 = NeuronGroup(5, 'v : volt', threshold='v > Vcut', reset='v = Vr', method='euler')  # Presynaptic neurons\n",
    "G2 = NeuronGroup(5, eqs, threshold='v > Vcut', reset='v = Vr; A += b', method='euler')  # Postsynaptic neurons\n",
    "\n",
    "# Initialize variables\n",
    "G1.v = EL\n",
    "G2.v = EL\n",
    "G2.A = 0 * nA\n",
    "\n",
    "# Create synapses\n",
    "S = Synapses(G1, G2, model=syn_eqs_exc,\n",
    "             on_pre='Y_post = 1*volt', method = \"euler\")  # Increment glutamate release on spike\n",
    "S.connect(p=0.1)  # Random connections\n",
    "S.w = 'rand() * w_init'  # Random initial weights\n",
    "\n",
    "# Monitors\n",
    "spike_mon_G1 = SpikeMonitor(G1)\n",
    "spike_mon_G2 = SpikeMonitor(G2)\n",
    "state_mon_G2 = StateMonitor(G2, ['v', 'I', 'A'], record=True)\n",
    "\n",
    "# Run simulation\n",
    "b2.run(500 * ms)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot membrane potential of a postsynaptic neuron\n",
    "plt.subplot(311)\n",
    "plt.plot(state_mon_G2.t / ms, state_mon_G2.v[0] / mV, label='Membrane potential (v)')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Voltage (mV)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# TODO: Make weights always non-negative!\n",
    "\n",
    "# Parameters for neurons\n",
    "Cm = 281 * pF  # Membrane capacitance\n",
    "gL = 30 * nS   # Leak conductance\n",
    "EL = -70.6 * mV  # Leak reversal potential\n",
    "Vth = -50.4 * mV  # Spike threshold\n",
    "DeltaT = 2 * mV  # Slope factor\n",
    "Vr = -70.6 * mV  # Reset potential\n",
    "Vcut = -40 * mV  # Cutoff potential for spike generation\n",
    "tau_A = 1 * ms  # Adaptation time constant\n",
    "c = 4 * nS       # Coupling parameter\n",
    "b = 0.0805 * nA  # Spike-triggered adaptation increment\n",
    "\n",
    "# Parameters for synapses\n",
    "tau_rise = 5 * ms  # Rise time constant for AMPA\n",
    "tau_decay = 50 * ms  # Decay time constant for NMDA\n",
    "w_init = 0.5 * nS   # Initial synaptic weight (conductance)\n",
    "\n",
    "# AdEx neuron equations\n",
    "eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + I - A ) / Cm : volt\n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "I : amp  # Input current\n",
    "'''\n",
    "\n",
    "input_eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + I - A ) / Cm : volt\n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "I = input_stimuli(t)  : amp  \n",
    "'''\n",
    "\n",
    "out_eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + I_tot - A ) / Cm : volt\n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "I : amp  # Synaptic input (summed)\n",
    "I_tot = I + output_stimuli(t, indices) : amp\n",
    "indices : integer  # dimensionless index variable\n",
    "'''\n",
    "\n",
    "# Synapse equations (Spike trace dynamics)\n",
    "\n",
    "\n",
    "syn_eqs_exc = '''\n",
    "dX/dt = -X / tau_decay + Y / tau_rise : volt   # Spike trace\n",
    "dY/dt = -Y / tau_decay : volt  # Glutamate decay\n",
    "w : siemens  # Synaptic weight (conductance)\n",
    "I_post = w * X : amp (summed)\n",
    "batch_sum_X : volt  # Accumulate X values over a batch\n",
    "running_sum_X : volt  # Sum of X during a stimulus\n",
    "'''\n",
    "\n",
    "syn_eqs_inh= '''\n",
    "dX/dt = -X / tau_decay + Y / tau_rise : volt  # Spike trace\n",
    "dY/dt = -Y / tau_decay : volt  # Glutamate decay\n",
    "w : siemens  # Synaptic weight (conductance)\n",
    "I_post = w * X : amp (summed)\n",
    "batch_sum_X : volt  # Accumulate X values over a batch\n",
    "running_sum_X : volt  # Sum of X during a stimulus\n",
    "'''\n",
    "\n",
    "def update_batch_sum(synapses):\n",
    "    synapses.batch_sum_X += synapses.X  # Perform the operation\n",
    "# Update logic\n",
    "@network_operation(dt = batch_size * msec_step * ms)\n",
    "def update_sums( ):\n",
    "\n",
    "    current_idx = int(defaultclock.t / msec_step*ms)\n",
    "    \n",
    "    if stimulus_indexes.values[current_idx] == 1:\n",
    "\n",
    "        \n",
    "        for n in range(len(Rs)-1):\n",
    "\n",
    "            for i in range(len(Rs[n])):\n",
    " \n",
    "                '''\n",
    "                Rs[n].batch_sum_X[i] += Rs[n].X_[i]\n",
    "                \n",
    "                Es_0[n].batch_sum_X[i] += Es_0[n].X_[i]\n",
    "    \n",
    "                Es_1[n].batch_sum_X[i] += Es_1[n].X_[i]\n",
    "                '''\n",
    "\n",
    "                Rs[n].batch_sum_X += Rs[n].X_\n",
    "                Es_0[n].batch_sum_X += Es_0[n].X_\n",
    "                Es_1[n].batch_sum_X += Es_1[n].X_\n",
    "        \n",
    "            \n",
    "@network_operation( dt = batch_size * msec_step * ms )\n",
    "def apply_weight_update():\n",
    "    \n",
    "    print(\"Applying weight update\")\n",
    "    \n",
    "    for n in range(len(Rs)-1):\n",
    "        print(\"n: \", n)\n",
    "        \n",
    "        for i in range(len(Rs[n])):\n",
    "            print(\"i: \", i)\n",
    "            for j in range(len(Es_0[n])):\n",
    "                print(\"j: \", j)\n",
    "    \n",
    "            \n",
    "                S_p, S_m = connections[f\"top_down_{n}\"]\n",
    "    \n",
    "                S_p.w[i,j] += lr * Es_0[n].batch_sum_X[j] * Rs[n].batch_sum_X[i] * siemens\n",
    "                \n",
    "                S_m.w[i,j] += lr * Es_1[n].batch_sum_X[j] * Rs[n].batch_sum_X[i]  * siemens\n",
    "            \n",
    "                Rs[n].batch_sum_X[i] = 0\n",
    "                \n",
    "                Es_0[n].batch_sum_X[i]= 0\n",
    "    \n",
    "                Es_1[n].batch_sum_X[i] = 0\n",
    "\n",
    "\n",
    "\n",
    "for stimulus_indexes, output_stimuli, input_stimuli in dl:\n",
    "\n",
    "    print(\"indexes\", stimulus_indexes.values.shape, stimulus_indexes.values)\n",
    "\n",
    "    run((batch_size + batch_size*num_pause_blocks) * 100 * ms)\n",
    "\n",
    "    \n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
