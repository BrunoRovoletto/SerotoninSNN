{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf135fe-7b03-4cf9-b41b-0d2a5218a2a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "executionInfo": {
     "elapsed": 731,
     "status": "error",
     "timestamp": 1733954486930,
     "user": {
      "displayName": "Cathy V",
      "userId": "00379111358150357952"
     },
     "user_tz": -60
    },
    "id": "cbf135fe-7b03-4cf9-b41b-0d2a5218a2a3",
    "outputId": "2c65b234-1fad-48ef-9bfe-decdcbf18f82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO       The following preferences have been changed for Brian2GeNN, reset them manually if you use a different device later in the same script: codegen.loop_invariant_optimisations, core.network.default_schedule [brian2.devices.genn]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import brian2 as b2\n",
    "from brian2 import *\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from dataset_util import Synthetic_Dataset_Utils\n",
    "\n",
    "\n",
    "import brian2genn\n",
    "\n",
    "\n",
    "\n",
    "set_device('genn', use_GPU=True)\n",
    "\n",
    "\n",
    "msec_step = 100\n",
    "shared_clock = Clock(dt=msec_step*ms)\n",
    "\n",
    "\n",
    "set_device('genn', use_GPU=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5675949a-f513-45a9-91ee-2ab7db85c35f",
   "metadata": {},
   "source": [
    "# TODO: Make weights always non-negative! (maybe not necessary)\n",
    "# Equations for everything. I_post in the synapse is modifying I in the target neuron\n",
    "\n",
    "\n",
    "# Parameters for neurons\n",
    "Cm = 281 * pF  # Membrane capacitance\n",
    "gL = 30 * nS   # Leak conductance\n",
    "EL = -70.6 * mV  # Leak reversal potential\n",
    "Vth = -50.4 * mV  # Spike threshold\n",
    "\n",
    "DeltaT = 2 * mV  # Slope factor\n",
    "Vr = -70.6 * mV  # Reset potential\n",
    "\n",
    "Vcut = -40 * mV  # Cutoff potential for spike generation\n",
    "tau_A = 1 * ms  # Adaptation time constant\n",
    "c = 4 * nS       # Coupling parameter\n",
    "b = 0.0805 * nA  # Spike-triggered adaptation increment\n",
    "\n",
    "# Parameters for synapses\n",
    "tau_rise = 5 * ms  # Rise time constant for AMPA\n",
    "tau_decay = 50 * ms  # Decay time constant for NMDA\n",
    "w_init = 0.5 * nS   # Initial synaptic weight (conductance)\n",
    "\n",
    "# AdEx neuron equations\n",
    "eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + Iexc + Iinh - A ) / Cm : volt \n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp \n",
    "dX/dt = -X / tau_decay + Y / tau_rise : volt   # Spike trace\n",
    "dY/dt = -Y / tau_decay : volt  # Glutamate decay \n",
    "Iexc : amp  \n",
    "Iinh : amp \n",
    "batch_sum_X : 1   # Accumulate X values over a batch\n",
    "running_sum_X : 1  # Sum of X during a stimulus\n",
    "'''\n",
    "# Ii = I + input_stimuli(t)  :  amp  # Input current\n",
    "\n",
    "\n",
    "input_eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + I - A ) / Cm : volt \n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp \n",
    "dX/dt = -X / tau_decay + Y / tau_rise : volt    # Spike trace\n",
    "dY/dt = -Y / tau_decay : volt  # Glutamate decay\n",
    "I = input_stimuli(t, indices) : amp \n",
    "indices : integer \n",
    "'''\n",
    "\n",
    "out_eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + I_tot - A ) / Cm : volt \n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "dX/dt = -X / tau_decay + Y / tau_rise : volt    # Spike trace\n",
    "dY/dt = -Y / tau_decay : volt  # Glutamate decay\n",
    "Iexc : amp  # Synaptic input \n",
    "Iexc2 : amp  # Synaptic input \n",
    "I_tot = Iexc + Iexc2 + output_stimuli(t, indices) : amp \n",
    "indices : integer  # dimensionless index variable\n",
    "'''\n",
    "\n",
    "# Synapse equations (Spike trace dynamics)\n",
    "\n",
    "\n",
    "syn_eqs_exc = '''\n",
    "w : siemens   # Synaptic weight, conductance\n",
    "Iexc_post = w * X_pre : amp (summed)\n",
    "'''\n",
    "\n",
    "syn_eqs_exc_output = '''\n",
    "w : siemens   # Synaptic weight, conductance\n",
    "Iexc2_post = w * X_pre : amp (summed)\n",
    "'''\n",
    "\n",
    "syn_eqs_inh= '''\n",
    "w : siemens   # Synaptic weight, conductance\n",
    "Iinh_post = w * X_pre : amp (summed)\n",
    "'''\n",
    "\n",
    "def update_batch_sum(synapses):\n",
    "    synapses.batch_sum_X += synapses.X  # Perform the operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197e3ac8-2cd3-487a-84f8-ffbe0d31e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make weights always non-negative!\n",
    "\n",
    "\n",
    "# Equations for everything. I_post in the synapse is modifying I in the target neuron\n",
    "\n",
    "\n",
    "# Parameters for neurons\n",
    "Cm = 281 * pF  # Membrane capacitance\n",
    "gL = 30 * nS   # Leak conductance\n",
    "EL = -70.6 * mV  # Leak reversal potential\n",
    "Vth = -50.4 * mV  # Spike threshold\n",
    "\n",
    "DeltaT = 2 * mV  # Slope factor\n",
    "Vr = -70.6 * mV  # Reset potential\n",
    "\n",
    "Vcut = -40 * mV  # Cutoff potential for spike generation\n",
    "tau_A = 1 * ms  # Adaptation time constant\n",
    "c = 4 * nS       # Coupling parameter\n",
    "b = 0.0805 * nA  # Spike-triggered adaptation increment\n",
    "\n",
    "# Parameters for synapses\n",
    "tau_rise = 5 * ms  # Rise time constant for AMPA\n",
    "tau_decay = 50 * ms  # Decay time constant for NMDA\n",
    "w_init = 0.5 * nS   # Initial synaptic weight (conductance)\n",
    "\n",
    "\n",
    "\n",
    "eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + Iexc + Iinh - A ) / Cm : volt \n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "dX/dt = -X / tau_decay + Y / tau_rise : volt   # Spike trace\n",
    "dY/dt = -Y / tau_decay : volt  # Glutamate decay \n",
    "Iexc : amp\n",
    "Iinh : amp\n",
    "batch_sum_X : 1   # Accumulate X values over a batch\n",
    "running_sum_X : 1  # Sum of X during a stimulus\n",
    "'''\n",
    "\n",
    "input_eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + I - A ) / Cm : volt \n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp \n",
    "dX/dt = -X / tau_decay + Y / tau_rise : volt   # Spike trace\n",
    "dY/dt = -Y / tau_decay : volt  # Glutamate decay\n",
    "I = input_stimuli(t, indices) : amp\n",
    "indices : integer\n",
    "'''\n",
    "\n",
    "out_eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT)\n",
    "          + Iexc + Iexc2 + output_stimuli(t, indices) - A ) / Cm : volt\n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "dX/dt = -X / tau_decay + Y / tau_rise : volt    # Spike trace\n",
    "dY/dt = -Y / tau_decay : volt  # Glutamate decay\n",
    "Iexc : amp  # Synaptic input\n",
    "Iexc2 : amp # Synaptic input\n",
    "indices : integer\n",
    "'''\n",
    "\n",
    "syn_eqs_exc = '''\n",
    "w : siemens   # Synaptic weight, conductance\n",
    "Iexc_post += w * X_pre : amp (summed)\n",
    "'''\n",
    "\n",
    "syn_eqs_exc_output = '''\n",
    "w : siemens   # Synaptic weight, conductance\n",
    "Iexc2_post += w * X_pre : amp (summed)\n",
    "'''\n",
    "\n",
    "syn_eqs_inh = '''\n",
    "w : siemens   # Synaptic weight, conductance\n",
    "Iinh_post += w * X_pre : amp (summed)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4cda873-deff-49bb-87b2-c6f1a89fea8f",
   "metadata": {
    "id": "e4cda873-deff-49bb-87b2-c6f1a89fea8f"
   },
   "outputs": [],
   "source": [
    "# dims = [784,400,225,64]\n",
    "dims = [50,40,30,20]\n",
    "\n",
    "gist_dim = 16\n",
    "\n",
    "# Just a function to make neurongroups of specified dimension. Assigns input equations (which read the input timedarray, hopefully) \n",
    "# to the first group if with_input = True\n",
    "def make_groups(dims, eqs = eqs, with_input = False):\n",
    "\n",
    "    groups = []\n",
    "\n",
    "    for i, dim in enumerate(dims):\n",
    "    \n",
    "        if i == 0 and with_input == True:\n",
    "    \n",
    "            groups.append(NeuronGroup(dim, input_eqs, threshold='v > Vcut', reset='v = Vr', method='euler'))\n",
    "    \n",
    "        else:\n",
    "    \n",
    "            groups.append(NeuronGroup(dim, eqs, threshold='v > Vcut', reset='v = Vr', method='euler'))\n",
    "    \n",
    "    for group in groups:\n",
    "        \n",
    "        group.v = EL\n",
    "    \n",
    "    \n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1632fe95-ea62-4a1c-b39d-200e31caea12",
   "metadata": {
    "id": "1632fe95-ea62-4a1c-b39d-200e31caea12"
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_bottom_up_connections(R, E_0, E_1, syn_eqs_exc, syn_eqs_inh):\n",
    "\n",
    "\n",
    "  S_p = Synapses(R, E_0, model=syn_eqs_exc,\n",
    "        on_pre='Y_post = 1*volt ')\n",
    "\n",
    "    \n",
    "  S_p.connect(condition='i == j')  # One-to-one connections\n",
    "  S_p.w = 'w_init'\n",
    "\n",
    "\n",
    "  S_m = Synapses(R, E_1, model=syn_eqs_inh,\n",
    "        on_pre='Y_post = 1*volt')\n",
    "  S_m.connect(condition='i == j')  # One-to-one connections\n",
    "  S_m.w = 'w_init'\n",
    "\n",
    "  return S_p, S_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lgB5lkb8fdCc",
   "metadata": {
    "id": "lgB5lkb8fdCc"
   },
   "outputs": [],
   "source": [
    "def make_top_down_connections(R, E_0, E_1, syn_eqs_exc, syn_eqs_inh):\n",
    "\n",
    "\n",
    "  S_p = Synapses(R, E_1, model=syn_eqs_exc,\n",
    "        on_pre='Y_post = 1*volt')\n",
    "  S_p.connect()\n",
    "  S_p.w = 'rand() * w_init'\n",
    "\n",
    "\n",
    "  S_m = Synapses(R, E_0, model=syn_eqs_inh,\n",
    "        on_pre='Y_post = 1*volt')\n",
    "  S_m.connect()\n",
    "  S_m.w = 'rand() * w_init'\n",
    "\n",
    "\n",
    "  return S_p, S_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ZBCZOcD97VdQ",
   "metadata": {
    "id": "ZBCZOcD97VdQ"
   },
   "outputs": [],
   "source": [
    "def make_gist_connections(Rs, G):\n",
    "\n",
    "  S = Synapses(Rs[0], G, model=syn_eqs_exc,\n",
    "        on_pre='Y_post = 1*volt')\n",
    "  S.connect(p=0.05)  # Connect with 5% probability\n",
    "  S.w = 'rand() * w_init'   # This is slightly different from the paper: it should be based on a ratio\n",
    "\n",
    "  S_gist_input = S\n",
    "\n",
    "  for R in Rs[1:]:\n",
    "    S = Synapses(G, R, model=syn_eqs_exc,\n",
    "        on_pre='Y_post = 1*volt')\n",
    "    S.connect(p=0.05)  # Connect with 5% probability\n",
    "    S_gist_output = S\n",
    "\n",
    "  return S_gist_input, S_gist_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "yKTMede3Unyd",
   "metadata": {
    "id": "yKTMede3Unyd"
   },
   "outputs": [],
   "source": [
    "# num_classes_per_layer and max_depth depend on the same parameters used when generating the datset\n",
    "\n",
    "def make_output_layer(num_classes_per_layer, max_depth, w_out_init = None ):\n",
    "\n",
    "    if w_out_init == None:\n",
    "        w_out_init = w_init/10\n",
    "        \n",
    "        \n",
    "\n",
    "    total_neurons = sum([num_classes_per_layer**(d+1) for d in range(max_depth)])\n",
    "    \n",
    "    \n",
    "    Os = NeuronGroup(N=total_neurons, model = out_eqs, threshold='v > Vcut', reset='v = Vr', method='euler')\n",
    "\n",
    "    \n",
    "\n",
    "    S_o = Synapses(Os, Os, model=syn_eqs_exc_output, on_pre='Y_post = 1*volt')\n",
    "    \n",
    "    trace = 0\n",
    "    for d in range(num_classes_per_layer - 1):\n",
    "\n",
    "        new_trace = trace + num_classes_per_layer**(d+1)\n",
    "        \n",
    "        source_indices = list(range(trace, trace + num_classes_per_layer**(d+1)))\n",
    "        target_indices = list(range(new_trace , new_trace + num_classes_per_layer**(d+2)))\n",
    "\n",
    "        ii, jj = np.meshgrid(source_indices, target_indices, indexing='ij')\n",
    "        \n",
    "        S_o.connect(i=ii.flatten(), j=jj.flatten())\n",
    "\n",
    "        trace = new_trace\n",
    "\n",
    "\n",
    "    stimulus_indices = []\n",
    "\n",
    "    for i, n in enumerate([num_classes_per_layer**i for i in range(1, max_depth+1)]):\n",
    "        for _ in range(n):\n",
    "            stimulus_indices.append(int(i))\n",
    "            \n",
    "    Os.indices = stimulus_indices \n",
    "\n",
    "\n",
    "    return Os, S_o\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0HO2o7eGvf0C",
   "metadata": {
    "id": "0HO2o7eGvf0C"
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_network(dims, syn_eqs_exc, syn_eqs_inh, num_classes_per_layer, max_depth, w_out_init = None ):\n",
    "\n",
    "    max_depth += 1\n",
    "    \n",
    "    Rs = make_groups(dims, with_input = True)\n",
    "    Es_0 = make_groups(dims[:-1])\n",
    "    Es_1 = make_groups(dims[:-1])\n",
    "    G = NeuronGroup(gist_dim, eqs, threshold='v > Vcut', reset='v = Vr', method='euler')\n",
    "    \n",
    "    Os, S_o_internal = make_output_layer(num_classes_per_layer, max_depth) # Hopefully this is correct\n",
    "    \n",
    "    connections = {}\n",
    "    connections[\"output_internal\"] = S_o_internal\n",
    "    \n",
    "    for i in range(len(Rs)-1):\n",
    "    \n",
    "    \n",
    "        S_p, S_m = make_bottom_up_connections(Rs[i], Es_0[i], Es_1[i], syn_eqs_exc, syn_eqs_inh)\n",
    "        \n",
    "        connections[f\"bottom_up_{i}\"] = [S_p, S_m]\n",
    "    \n",
    "        if i != len(Rs)-1:\n",
    "        \n",
    "            S_p, S_m = make_top_down_connections(Rs[i+1], Es_0[i], Es_1[i], syn_eqs_exc, syn_eqs_inh)\n",
    "            \n",
    "            connections[f\"top_down_{i}\"] = [S_p, S_m]\n",
    "        \n",
    "    S_gist_input, S_gist_output = make_gist_connections(Rs, G)\n",
    "    \n",
    "    connections[\"gist_input\"] = S_gist_input\n",
    "    connections[\"gist_output\"] = S_gist_output\n",
    "    \n",
    "    '''\n",
    "    S_o_external = Synapses(Rs[-1], Os, model=syn_eqs_exc,\n",
    "        on_pre='Y_post = 1*volt')\n",
    "    S_o_external.connect()\n",
    "    S_o_external.w = 'rand() * w_init'\n",
    "    '''\n",
    "    S_o_external = []\n",
    "    for O in Os:\n",
    "        S = Synapses(Rs[-1], O, model=syn_eqs_exc, on_pre='Y_post = 1*volt')\n",
    "        S.connect()\n",
    "        S.w = 'rand() * w_init'\n",
    "        S_o_external.append(S)\n",
    "    connections[\"output_external\"] = S_o_external\n",
    "\n",
    "\n",
    "    return Rs, Es_0, Es_1, G, S_gist_input, S_gist_output, Os, S_o_external, connections\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fab0d6-5862-442a-8f30-a43f29742762",
   "metadata": {},
   "source": [
    "# Helpful for setting up input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef16053a-1a23-4a21-9099-2f384c0d0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tensor(tensor, old_min, old_max, new_min, new_max):\n",
    "\n",
    "    normalized_tensor = (tensor - old_min) / (old_max - old_min)\n",
    "\n",
    "\n",
    "    scaled_tensor = normalized_tensor * (new_max - new_min) + new_min\n",
    "\n",
    "    return scaled_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22cb22e1-5d5b-42fc-892a-93277adcfe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_unwrap_dataset(dt, minval,maxval):\n",
    "\n",
    "\n",
    "    minimum = 0\n",
    "    maximum = 0\n",
    "    \n",
    "    all_curves = [torch.tensor(curve, dtype = torch.float64) for curve in chain.from_iterable(dt[\"curves\"].values())]\n",
    "    \n",
    "    for curve in all_curves:\n",
    "    \n",
    "        _min = torch.min(curve)\n",
    "        _max = torch.max(curve)\n",
    "        if(minimum > _min): minimum = _min\n",
    "        if(maximum < _max): maximum = _max\n",
    "\n",
    "\n",
    "    unwrapped = []\n",
    "    for key in dt[\"categories\"].keys():\n",
    "        for curve in dt[\"curves\"][key]:\n",
    "            unwrapped.append((torch.tensor(key), normalize_tensor(torch.tensor(curve), minimum, maximum, minval, maxval)))\n",
    "            \n",
    "    return unwrapped\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7899bab7-8b66-496f-80a3-89e3490c3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_stimuli_indexes_from_labels(labels, num_classes_per_layer):\n",
    "\n",
    "    if labels.ndim == 1:\n",
    "        labels = labels.unsqueeze(0)  # Convert to 2D with shape (1, len(I_indexes))\n",
    "\n",
    "    indexes = torch.zeros_like(labels)\n",
    "    \n",
    "    for i in range(0, labels.shape[1]):\n",
    "    \n",
    "        summed = 0\n",
    "        if i>0:\n",
    "            summed = torch.stack([labels[:,j]*num_classes_per_layer**(i-j) for j in range(i)]).sum(dim=0)\n",
    "    \n",
    "        indexes[:,i] = summed + labels[:,i] # These are more intelligible, since they indicate which neuron to stimulate for each level of granularity\n",
    "\n",
    "    # But we need to adapt them for a situation where all neurons are concatenated in a single list\n",
    "    \n",
    "    to_sum = 0\n",
    "    for i in range(0, labels.shape[1]):\n",
    "\n",
    "        if i>0:\n",
    "            to_sum += num_classes_per_layer**i \n",
    "\n",
    "        indexes[:,i] = indexes[:,i] + to_sum\n",
    "\n",
    "    return indexes\n",
    "\n",
    "\n",
    "\n",
    "def get_output_current_arrays(I_indexes, dim, I_value):\n",
    "    # Ensure I_indexes is 2D for consistent processing\n",
    "    if I_indexes.ndim == 1:\n",
    "        I_indexes = I_indexes.unsqueeze(0)  # Convert to 2D with shape (1, len(I_indexes))\n",
    "\n",
    "    # Create an output tensor of zeros\n",
    "    out = torch.zeros((I_indexes.shape[0], dim), dtype=torch.float32)\n",
    "\n",
    "    # Row indices (batch indices) for advanced indexing\n",
    "    row_indices = torch.arange(I_indexes.shape[0]).repeat_interleave(I_indexes.shape[1])\n",
    "\n",
    "    # Flattened column indices (curve indexes)\n",
    "    col_indices = I_indexes.flatten()\n",
    "\n",
    "    # Set the values using advanced indexing\n",
    "    out[row_indices, col_indices] = I_value\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class CurveDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, minval, maxval):\n",
    "        \n",
    "        self.data = normalize_and_unwrap_dataset(data, minval, maxval)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        labels, curves = self.data[idx]\n",
    "      \n",
    "  \n",
    "        return labels, curves.flatten()\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn(batch, msec_step, num_pause_blocks, num_classes_per_layer, out_dim):\n",
    "\n",
    "    \n",
    "\n",
    "    labels, curves = zip(*batch)\n",
    "\n",
    "    labels = torch.stack(labels, dim=0)\n",
    "    curves = torch.stack(curves, dim=0)\n",
    "\n",
    "\n",
    "   \n",
    "    pause = torch.zeros_like(curves[0])  \n",
    "    \n",
    "    pause_block = torch.tile(pause, (num_pause_blocks, 1))  \n",
    "    \n",
    "    # Interleave stimulus rows with the pause block\n",
    "    curves_with_pause = torch.vstack([torch.vstack((row, pause_block)) for row in curves])\n",
    "\n",
    "    visual_stimulus = TimedArray(curves_with_pause.numpy() * nA, dt=msec_step*ms)\n",
    "\n",
    "\n",
    "    stimulus_indexes = TimedArray(np.tile([1] +\n",
    "                                     [0] * num_pause_blocks, curves.size(0)), dt=msec_step*ms)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    out_stimuli_idx = get_output_stimuli_indexes_from_labels(labels, num_classes_per_layer)\n",
    "   \n",
    "    out_stimuli_array = get_output_current_arrays(out_stimuli_idx, out_dim, 1)\n",
    "\n",
    "    label_pause = torch.zeros(out_dim)  \n",
    "    \n",
    "    label_pause_block = torch.tile(label_pause, (num_pause_blocks, 1)) \n",
    "\n",
    "    out_stimuli_with_pause = torch.vstack([torch.vstack((row, label_pause_block)) for row in out_stimuli_array])\n",
    "\n",
    "    output_stimuli = TimedArray(out_stimuli_with_pause.numpy() * nA, dt=msec_step*ms) \n",
    "    \n",
    "\n",
    " \n",
    "    \n",
    "\n",
    "    return stimulus_indexes, output_stimuli , visual_stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac4d286-c534-47b9-a39f-2ddf03581a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00477b05-4925-44dc-bf39-04b4b7cc1819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce057cf3-0c48-460e-b499-cf6b31e37f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16871412-6ac8-4121-886b-8e605ba8bc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fa69c0b-f02f-4d63-b488-40bc7758c46a",
   "metadata": {},
   "outputs": [
    {
     "ename": "EquationError",
     "evalue": "Parsing failed: \nIexc2_post += w * X_pre : amp (summed)\n^\nExpected end of text, found 'Iexc2'  (at char 46), (line:3, col:1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\AI 2024-25\\Programming_utils\\envs\\neural_computation_env\\Lib\\site-packages\\brian2\\equations\\equations.py:386\u001b[0m, in \u001b[0;36mparse_string_equations\u001b[1;34m(eqns)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m     parsed \u001b[38;5;241m=\u001b[39m \u001b[43mEQUATIONS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparseString\u001b[49m\u001b[43m(\u001b[49m\u001b[43meqns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparseAll\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParseException \u001b[38;5;28;01mas\u001b[39;00m p_exc:\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\AI 2024-25\\Programming_utils\\envs\\neural_computation_env\\Lib\\site-packages\\pyparsing\\util.py:256\u001b[0m, in \u001b[0;36mreplaced_by_pep8.<locals>._inner\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_inner\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;66;03m# warnings.warn(\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;66;03m#     f\"Deprecated - use {fn.__name__}\", DeprecationWarning, stacklevel=2\u001b[39;00m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\AI 2024-25\\Programming_utils\\envs\\neural_computation_env\\Lib\\site-packages\\pyparsing\\core.py:1199\u001b[0m, in \u001b[0;36mParserElement.parse_string\u001b[1;34m(self, instring, parse_all, parseAll)\u001b[0m\n\u001b[0;32m   1197\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1198\u001b[0m         \u001b[38;5;66;03m# catch and re-raise exception from here, clearing out pyparsing internal stack trace\u001b[39;00m\n\u001b[1;32m-> 1199\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mParseException\u001b[0m: Expected end of text, found 'Iexc2'  (at char 46), (line:3, col:1)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mEquationError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dims \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m Rs, Es_0, Es_1, G, S_gist_input, S_gist_output, Os, S_o_external, connections \u001b[38;5;241m=\u001b[39m \u001b[43mmake_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msyn_eqs_exc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msyn_eqs_inh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes_per_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m Rs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mindices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(Rs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mN)\n",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m, in \u001b[0;36mmake_network\u001b[1;34m(dims, syn_eqs_exc, syn_eqs_inh, num_classes_per_layer, max_depth, w_out_init)\u001b[0m\n\u001b[0;32m      7\u001b[0m Es_1 \u001b[38;5;241m=\u001b[39m make_groups(dims[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      8\u001b[0m G \u001b[38;5;241m=\u001b[39m NeuronGroup(gist_dim, eqs, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv > Vcut\u001b[39m\u001b[38;5;124m'\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv = Vr\u001b[39m\u001b[38;5;124m'\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuler\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m Os, S_o_internal \u001b[38;5;241m=\u001b[39m \u001b[43mmake_output_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes_per_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Hopefully this is correct\u001b[39;00m\n\u001b[0;32m     12\u001b[0m connections \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     13\u001b[0m connections[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_internal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m S_o_internal\n",
      "Cell \u001b[1;32mIn[7], line 17\u001b[0m, in \u001b[0;36mmake_output_layer\u001b[1;34m(num_classes_per_layer, max_depth, w_out_init)\u001b[0m\n\u001b[0;32m     10\u001b[0m total_neurons \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([num_classes_per_layer\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(d\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_depth)])\n\u001b[0;32m     13\u001b[0m Os \u001b[38;5;241m=\u001b[39m NeuronGroup(N\u001b[38;5;241m=\u001b[39mtotal_neurons, model \u001b[38;5;241m=\u001b[39m out_eqs, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv > Vcut\u001b[39m\u001b[38;5;124m'\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv = Vr\u001b[39m\u001b[38;5;124m'\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuler\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m S_o \u001b[38;5;241m=\u001b[39m \u001b[43mSynapses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msyn_eqs_exc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_pre\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mY_post = 1*volt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m trace \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_classes_per_layer \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\AI 2024-25\\Programming_utils\\envs\\neural_computation_env\\Lib\\site-packages\\brian2\\synapses\\synapses.py:845\u001b[0m, in \u001b[0;36mSynapses.__init__\u001b[1;34m(self, source, target, model, on_pre, pre, on_post, post, connect, delay, on_event, multisynaptic_index, namespace, dtype, codeobj_class, dt, clock, order, method, method_options, name)\u001b[0m\n\u001b[0;32m    842\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 845\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mEquations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Equations):\n\u001b[0;32m    847\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel has to be a string or an Equations \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject, is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    850\u001b[0m     )\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\AI 2024-25\\Programming_utils\\envs\\neural_computation_env\\Lib\\site-packages\\brian2\\equations\\equations.py:619\u001b[0m, in \u001b[0;36mEquations.__init__\u001b[1;34m(self, eqns, **kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, eqns, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(eqns, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_equations \u001b[38;5;241m=\u001b[39m \u001b[43mparse_string_equations\u001b[49m\u001b[43m(\u001b[49m\u001b[43meqns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m         \u001b[38;5;66;03m# Do a basic check for the identifiers\u001b[39;00m\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_identifiers()\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\AI 2024-25\\Programming_utils\\envs\\neural_computation_env\\Lib\\site-packages\\brian2\\utils\\caching.py:107\u001b[0m, in \u001b[0;36mcached.<locals>.cached_func\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m     func\u001b[38;5;241m.\u001b[39m_cache_statistics\u001b[38;5;241m.\u001b[39mmisses \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 107\u001b[0m     func\u001b[38;5;241m.\u001b[39m_cache[cache_key] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\u001b[38;5;241m.\u001b[39m_cache[cache_key]\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\AI 2024-25\\Programming_utils\\envs\\neural_computation_env\\Lib\\site-packages\\brian2\\equations\\equations.py:388\u001b[0m, in \u001b[0;36mparse_string_equations\u001b[1;34m(eqns)\u001b[0m\n\u001b[0;32m    386\u001b[0m     parsed \u001b[38;5;241m=\u001b[39m EQUATIONS\u001b[38;5;241m.\u001b[39mparseString(eqns, parseAll\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParseException \u001b[38;5;28;01mas\u001b[39;00m p_exc:\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EquationError(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParsing failed: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(p_exc\u001b[38;5;241m.\u001b[39mline)\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m (p_exc\u001b[38;5;241m.\u001b[39mcolumn \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(p_exc)\n\u001b[0;32m    395\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mp_exc\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eq \u001b[38;5;129;01min\u001b[39;00m parsed:\n\u001b[0;32m    397\u001b[0m     eq_type \u001b[38;5;241m=\u001b[39m eq\u001b[38;5;241m.\u001b[39mgetName()\n",
      "\u001b[1;31mEquationError\u001b[0m: Parsing failed: \nIexc2_post += w * X_pre : amp (summed)\n^\nExpected end of text, found 'Iexc2'  (at char 46), (line:3, col:1)"
     ]
    }
   ],
   "source": [
    "dims = [2, 2,2,2]\n",
    "Rs, Es_0, Es_1, G, S_gist_input, S_gist_output, Os, S_o_external, connections = make_network(dims, syn_eqs_exc, syn_eqs_inh, num_classes_per_layer=3, max_depth=3)\n",
    "\n",
    "Rs[0].indices = range(Rs[0].N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e07d4a-7015-4980-824b-6c82bfaef728",
   "metadata": {},
   "outputs": [],
   "source": [
    "su = Synthetic_Dataset_Utils()\n",
    "\n",
    "ranges = [30,30,30,30]  # Ranges for each parameter\n",
    "\n",
    "prior_params = [10,10,10,10]  # Initial parameters\n",
    "\n",
    "num_samples_per_class=5\n",
    "N=15\n",
    "\n",
    "# Build the tree\n",
    "max_depth = 3 # Adjust as needed\n",
    "num_classes_per_layer = 3  # Adjust as needed\n",
    "\n",
    "std_multiplier = 1\n",
    "\n",
    "tree = su.build_tree(prior_params, 0, max_depth, num_classes_per_layer, std_multiplier, ranges)\n",
    "\n",
    "synth_dataset = su.make_dataset(tree, num_samples_per_class=num_samples_per_class, N=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4fa470-20a2-424b-b831-eae2887e6576",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = sum([len(o) for o in Os])\n",
    "\n",
    "lr = 0.03\n",
    "msec_step = 500\n",
    "batch_size = 20\n",
    "num_pause_blocks = 1\n",
    "\n",
    "dataset = CurveDataset(synth_dataset, 0.6, 1.5)\n",
    "dl = DataLoader( dataset, shuffle = True, batch_size = batch_size, collate_fn = partial(collate_fn, msec_step=msec_step, num_pause_blocks=num_pause_blocks,\n",
    "                                                                                num_classes_per_layer = num_classes_per_layer, out_dim = output_dim) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ace3fd-57b0-4fbd-8f3e-e8c741a6c1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update logic\n",
    "@network_operation()\n",
    "def add_inputs():\n",
    "    stimulus_indexes = _stimulus_indexes \n",
    "    output_stimuli = _output_stimuli\n",
    "    input_stimuli = _input_stimuli\n",
    "\n",
    "@network_operation()\n",
    "def debug():\n",
    "    print(\"Rs[0].I: \", Rs[0].I[:])\n",
    "   \n",
    "@network_operation()\n",
    "def update_sums():\n",
    "\n",
    "    current_idx = int(defaultclock.t / msec_step*ms)\n",
    "    \n",
    "    if stimulus_indexes.values[current_idx] == 1:\n",
    "\n",
    "        \n",
    "        for n in range(len(Rs)-1):\n",
    "\n",
    "            if n > 0:\n",
    "                Rs[n+1].batch_sum_X += Rs[n+1].X_\n",
    "                \n",
    "            Es_0[n].batch_sum_X += Es_0[n].X_\n",
    "            Es_1[n].batch_sum_X += Es_1[n].X_\n",
    "\n",
    "            \n",
    "@network_operation()\n",
    "def apply_weight_update():\n",
    "    \n",
    "    print(\"Applying weight update\")\n",
    "    \n",
    "    for n in range(len(Rs)-1):\n",
    "\n",
    "        print(\"n: \", n)\n",
    "        \n",
    "        for i in range(len(Rs[n+1])):\n",
    "            for j in range(len(Es_0[n])):\n",
    "   \n",
    "            \n",
    "                S_p, S_m = connections[f\"top_down_{n}\"]\n",
    "    \n",
    "                S_p.w[i,j] += lr * Es_0[n].batch_sum_X[j] * Rs[n+1].batch_sum_X[i] * siemens\n",
    "                \n",
    "                S_m.w[i,j] += lr * Es_1[n].batch_sum_X[j] * Rs[n+1].batch_sum_X[i]  * siemens\n",
    "            \n",
    "                Rs[n+1].batch_sum_X[i] = 0\n",
    "                \n",
    "                Es_0[n].batch_sum_X[i]= 0\n",
    "    \n",
    "                Es_1[n].batch_sum_X[i] = 0\n",
    "\n",
    "\n",
    "stimulus_indexes, output_stimuli, input_stimuli = next(iter(dl))\n",
    "\n",
    "monitor = StateMonitor(Rs[0], ['v', 'I'], record=[0])\n",
    "spike_monitor = SpikeMonitor(Rs[0])\n",
    "\n",
    "net = Network(Rs, Es_0, Es_1, G,  Os, connections, monitor, spike_monitor, add_inputs, debug, update_sums, apply_weight_update)\n",
    "\n",
    "for i, (_stimulus_indexes, _output_stimuli, _input_stimuli) in enumerate(dl):\n",
    "\n",
    "\n",
    "    print(f\"batch n.{i}\")\n",
    "\n",
    "\n",
    "\n",
    "    net.run((batch_size + batch_size*num_pause_blocks) * 100 * ms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc9e130-68f9-4344-9b90-2b7c73282fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce08c8d-27d0-436a-9035-650e84abaae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in net.objects:\n",
    "    print(f\"Object: {obj}, Clock: {obj.clock}, dt: {obj.clock.dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78240f2e-2cb9-40b1-9292-c8cb76210131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0058c166-80ed-464c-a75e-b37b36711d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74cc485-f4fe-47ea-8467-fe84cea25728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e20a8f-7e07-47f1-89c8-293c6e932b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4315ec3-5b6b-4220-b253-d315d30e6a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1cd3ab-992c-421b-98ea-43c36d53464d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140c791d-797d-4b45-9c58-9891429fba36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c778742e-37c3-439d-afb7-da728be51fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639ea6b-c9fa-4019-adef-734c4899d160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1dcc06-81d5-499d-9fce-eb8d7a9d089e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4485c9ac-195e-4221-a629-75af4422fcaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e49ef9-29d6-40be-a0b0-defbe2f36826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc5af8d-ad06-45e8-a0fe-5bd678943b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc7de56-20b5-4998-a35a-86e86f301bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(vars(spike_monitor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d5551-26cc-4093-88ac-28068d6dec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# spike_monitor = SpikeMonitor(Os)\n",
    "\n",
    "\n",
    "# Plot membrane potential\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "\n",
    "\n",
    "# Firing rate plot\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.hist(spike_monitor.t / ms, bins=10, alpha=0.7)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Spike Count')\n",
    "plt.title('Firing Rate of Neuron 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zkD5Zs72axi9",
   "metadata": {
    "id": "zkD5Zs72axi9"
   },
   "outputs": [],
   "source": [
    "def training_phase_1(network, dl):\n",
    "\n",
    "  for label_input, curve_input in dl:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lOfMXzfIaxdn",
   "metadata": {
    "id": "lOfMXzfIaxdn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T9V1Ufi3axau",
   "metadata": {
    "id": "T9V1Ufi3axau"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Membrane potential plot\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(monitor.t / ms, monitor.v[0] / mV, label='mV')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Membrane Potential (mV)')\n",
    "plt.title('Input')\n",
    "plt.legend()\n",
    "\n",
    "# Firing rate plot\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.hist(spike_monitor.t / ms, bins=10, alpha=0.7)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Spike Count')\n",
    "plt.title('Input')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jJZrHvJVaxXE",
   "metadata": {
    "id": "jJZrHvJVaxXE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ee7d2-a787-41b0-a184-154cbb8d3242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f51cc-b549-4b0c-83f2-eb6df4bfaf66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2226e1-6834-4dff-82e4-59e522ee9a81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99fb598-329c-41f4-8998-97d02000a5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719d563b-4185-43e6-b26a-41ae6cfdd1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "586f1b19-bab1-4990-b2ca-1aabe4ae053c",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc4819-5071-4651-9378-4a9ab4117d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network(\n",
    "    *Rs,        # Unpack the list of NeuronGroups\n",
    "    *Es_0,      # Unpack the list of NeuronGroups\n",
    "    *Es_1,      # Unpack the list of NeuronGroups\n",
    "    G,          # Single NeuronGroup is fine\n",
    "    Os,         # Single NeuronGroup is fine\n",
    "    connections[\"output_internal\"],   # Single Synapses object is fine\n",
    "    connections[\"gist_input\"],        # Single Synapses object is fine\n",
    "    *connections[\"gist_output\"],      # Unpack the list of Synapses\n",
    "    *connections[\"output_external\"],  # Unpack the list of Synapses\n",
    "    spike_monitor, \n",
    "    monitor,\n",
    "    debug, \n",
    "    update_sums, \n",
    "    apply_weight_update\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JUtGtvxAaxRO",
   "metadata": {
    "id": "JUtGtvxAaxRO"
   },
   "outputs": [],
   "source": [
    "eqs_neuron = '''\n",
    "dv/dt = (-gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + I - A) / Cm : volt\n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "I = stimulus(t)  : amp  \n",
    "'''\n",
    "\n",
    "\n",
    "neuron = make_groups([1], eqs = eqs_neuron)[0]\n",
    "\n",
    "neuron\n",
    "\n",
    "# Change 2 to any value from 0.6 to 1.5, which is the range of current intensity we are probably going to use\n",
    "\n",
    "stimulus = TimedArray(np.hstack([[c] for c in np.ones(1)*0.8]) * nA, dt=10*ms)\n",
    "\n",
    "\n",
    "\n",
    "neuron.v = EL\n",
    "neuron.A = 0 * nA\n",
    "\n",
    "# Monitor the specific neuron (neuron 2)\n",
    "monitor = StateMonitor(neuron, ['v', 'I'], record=[0])\n",
    "spike_monitor = SpikeMonitor(neuron)\n",
    "\n",
    "run(1 * second)\n",
    "\n",
    "# Plot membrane potential\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Membrane potential plot\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(monitor.t / ms, monitor.v[0] / mV, label='Neuron 2 Membrane Potential')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Membrane Potential (mV)')\n",
    "plt.title('Stimulus Applied to Single Neuron')\n",
    "plt.legend()\n",
    "\n",
    "# Firing rate plot\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.hist(spike_monitor.t / ms, bins=10, alpha=0.7)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Spike Count')\n",
    "plt.title('Firing Rate of Neuron 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "0.6: 0\n",
    "0.625: 0\n",
    "0.63: 0.5\n",
    "0.65: 1.5\n",
    "0.7: 2.8\n",
    "0.8: 4.5\n",
    "1: 7.5\n",
    "1.5: 14\n",
    "2: 20\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f18219-77eb-4144-8b49-d2df646ad21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's connect 2 groups as a trial\n",
    "\n",
    "G1 = NeuronGroup(5, 'v : volt', threshold='v > Vcut', reset='v = Vr', method='euler')  # Presynaptic neurons\n",
    "G2 = NeuronGroup(5, eqs, threshold='v > Vcut', reset='v = Vr; A += b', method='euler')  # Postsynaptic neurons\n",
    "\n",
    "# Initialize variables\n",
    "G1.v = EL\n",
    "G2.v = EL\n",
    "G2.A = 0 * nA\n",
    "\n",
    "# Create synapses\n",
    "S = Synapses(G1, G2, model=syn_eqs_exc,\n",
    "             on_pre='Y_post = 1*volt', method = \"euler\")  # Increment glutamate release on spike\n",
    "S.connect(p=0.1)  # Random connections\n",
    "S.w = 'rand() * w_init'  # Random initial weights\n",
    "\n",
    "# Monitors\n",
    "spike_mon_G1 = SpikeMonitor(G1)\n",
    "spike_mon_G2 = SpikeMonitor(G2)\n",
    "state_mon_G2 = StateMonitor(G2, ['v', 'I', 'A'], record=True)\n",
    "\n",
    "# Run simulation\n",
    "b2.run(500 * ms)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot membrane potential of a postsynaptic neuron\n",
    "plt.subplot(311)\n",
    "plt.plot(state_mon_G2.t / ms, state_mon_G2.v[0] / mV, label='Membrane potential (v)')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Voltage (mV)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33487b0-f5ed-4b97-9956-8a57570ef79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make weights always non-negative!\n",
    "\n",
    "# Parameters for neurons\n",
    "Cm = 281 * pF  # Membrane capacitance\n",
    "gL = 30 * nS   # Leak conductance\n",
    "EL = -70.6 * mV  # Leak reversal potential\n",
    "Vth = -50.4 * mV  # Spike threshold\n",
    "DeltaT = 2 * mV  # Slope factor\n",
    "Vr = -70.6 * mV  # Reset potential\n",
    "Vcut = -40 * mV  # Cutoff potential for spike generation\n",
    "tau_A = 1 * ms  # Adaptation time constant\n",
    "c = 4 * nS       # Coupling parameter\n",
    "b = 0.0805 * nA  # Spike-triggered adaptation increment\n",
    "\n",
    "# Parameters for synapses\n",
    "tau_rise = 5 * ms  # Rise time constant for AMPA\n",
    "tau_decay = 50 * ms  # Decay time constant for NMDA\n",
    "w_init = 0.5 * nS   # Initial synaptic weight (conductance)\n",
    "\n",
    "# AdEx neuron equations\n",
    "eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + I - A ) / Cm : volt\n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "I : amp  # Input current\n",
    "'''\n",
    "\n",
    "input_eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + I - A ) / Cm : volt\n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "I = input_stimuli(t)  : amp  \n",
    "'''\n",
    "\n",
    "out_eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + I_tot - A ) / Cm : volt\n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "I : amp  # Synaptic input (summed)\n",
    "I_tot = I + output_stimuli(t, indices) : amp\n",
    "indices : integer  # dimensionless index variable\n",
    "'''\n",
    "\n",
    "# Synapse equations (Spike trace dynamics)\n",
    "\n",
    "\n",
    "syn_eqs_exc = '''\n",
    "dX/dt = -X / tau_decay + Y / tau_rise : volt   # Spike trace\n",
    "dY/dt = -Y / tau_decay : volt  # Glutamate decay\n",
    "w : siemens  # Synaptic weight (conductance)\n",
    "I_post = w * X : amp (summed)\n",
    "batch_sum_X : volt  # Accumulate X values over a batch\n",
    "running_sum_X : volt  # Sum of X during a stimulus\n",
    "'''\n",
    "\n",
    "syn_eqs_inh= '''\n",
    "dX/dt = -X / tau_decay + Y / tau_rise : volt  # Spike trace\n",
    "dY/dt = -Y / tau_decay : volt  # Glutamate decay\n",
    "w : siemens  # Synaptic weight (conductance)\n",
    "I_post = w * X : amp (summed)\n",
    "batch_sum_X : volt  # Accumulate X values over a batch\n",
    "running_sum_X : volt  # Sum of X during a stimulus\n",
    "'''\n",
    "\n",
    "def update_batch_sum(synapses):\n",
    "    synapses.batch_sum_X += synapses.X  # Perform the operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f595c7b-4896-4d7e-8dfb-3590cd46a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update logic\n",
    "@network_operation(dt = batch_size * msec_step * ms)\n",
    "def update_sums( ):\n",
    "\n",
    "    current_idx = int(defaultclock.t / msec_step*ms)\n",
    "    \n",
    "    if stimulus_indexes.values[current_idx] == 1:\n",
    "\n",
    "        \n",
    "        for n in range(len(Rs)-1):\n",
    "\n",
    "            for i in range(len(Rs[n])):\n",
    " \n",
    "                '''\n",
    "                Rs[n].batch_sum_X[i] += Rs[n].X_[i]\n",
    "                \n",
    "                Es_0[n].batch_sum_X[i] += Es_0[n].X_[i]\n",
    "    \n",
    "                Es_1[n].batch_sum_X[i] += Es_1[n].X_[i]\n",
    "                '''\n",
    "\n",
    "                Rs[n].batch_sum_X += Rs[n].X_\n",
    "                Es_0[n].batch_sum_X += Es_0[n].X_\n",
    "                Es_1[n].batch_sum_X += Es_1[n].X_\n",
    "        \n",
    "            \n",
    "@network_operation( dt = batch_size * msec_step * ms )\n",
    "def apply_weight_update():\n",
    "    \n",
    "    print(\"Applying weight update\")\n",
    "    \n",
    "    for n in range(len(Rs)-1):\n",
    "        print(\"n: \", n)\n",
    "        \n",
    "        for i in range(len(Rs[n])):\n",
    "            print(\"i: \", i)\n",
    "            for j in range(len(Es_0[n])):\n",
    "                print(\"j: \", j)\n",
    "    \n",
    "            \n",
    "                S_p, S_m = connections[f\"top_down_{n}\"]\n",
    "    \n",
    "                S_p.w[i,j] += lr * Es_0[n].batch_sum_X[j] * Rs[n].batch_sum_X[i] * siemens\n",
    "                \n",
    "                S_m.w[i,j] += lr * Es_1[n].batch_sum_X[j] * Rs[n].batch_sum_X[i]  * siemens\n",
    "            \n",
    "                Rs[n].batch_sum_X[i] = 0\n",
    "                \n",
    "                Es_0[n].batch_sum_X[i]= 0\n",
    "    \n",
    "                Es_1[n].batch_sum_X[i] = 0\n",
    "\n",
    "\n",
    "\n",
    "for stimulus_indexes, output_stimuli, input_stimuli in dl:\n",
    "\n",
    "    print(\"indexes\", stimulus_indexes.values.shape, stimulus_indexes.values)\n",
    "\n",
    "    run((batch_size + batch_size*num_pause_blocks) * 100 * ms)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "neural_computation_kernel",
   "language": "python",
   "name": "neural_computation_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
