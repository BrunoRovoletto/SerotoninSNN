{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf135fe-7b03-4cf9-b41b-0d2a5218a2a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "executionInfo": {
     "elapsed": 731,
     "status": "error",
     "timestamp": 1733954486930,
     "user": {
      "displayName": "Cathy V",
      "userId": "00379111358150357952"
     },
     "user_tz": -60
    },
    "id": "cbf135fe-7b03-4cf9-b41b-0d2a5218a2a3",
    "outputId": "2c65b234-1fad-48ef-9bfe-decdcbf18f82"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import brian2 as b2\n",
    "from brian2 import *\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from dataset_util import Synthetic_Dataset_Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7335fb-7ebf-490d-a73e-633827e90ee9",
   "metadata": {
    "id": "fc7335fb-7ebf-490d-a73e-633827e90ee9"
   },
   "outputs": [],
   "source": [
    "# TODO: Make weights always non-negative!\n",
    "\n",
    "# Parameters for neurons\n",
    "Cm = 281 * pF  # Membrane capacitance\n",
    "gL = 30 * nS   # Leak conductance\n",
    "EL = -70.6 * mV  # Leak reversal potential\n",
    "Vth = -50.4 * mV  # Spike threshold\n",
    "DeltaT = 2 * mV  # Slope factor\n",
    "Vr = -70.6 * mV  # Reset potential\n",
    "Vcut = -40 * mV  # Cutoff potential for spike generation\n",
    "tau_A = 1 * ms  # Adaptation time constant\n",
    "c = 4 * nS       # Coupling parameter\n",
    "b = 0.0805 * nA  # Spike-triggered adaptation increment\n",
    "\n",
    "# Parameters for synapses\n",
    "tau_rise = 5 * ms  # Rise time constant for AMPA\n",
    "tau_decay = 50 * ms  # Decay time constant for NMDA\n",
    "w_init = 0.5 * nS   # Initial synaptic weight (conductance)\n",
    "\n",
    "# AdEx neuron equations\n",
    "eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + I - A ) / Cm : volt\n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "I : amp  # Input current\n",
    "'''\n",
    "\n",
    "input_eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + I - A ) / Cm : volt\n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "I = input_stimuli(t)  : amp  \n",
    "'''\n",
    "\n",
    "out_eqs = '''\n",
    "dv/dt = ( -gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + I_tot - A ) / Cm : volt\n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "I : amp  # Synaptic input (summed)\n",
    "I_tot = I + output_stimuli(t, indices) : amp\n",
    "indices : integer  # dimensionless index variable\n",
    "'''\n",
    "\n",
    "# Synapse equations (Spike trace dynamics)\n",
    "syn_eqs_exc = '''\n",
    "dX/dt = -X / tau_decay + Y / tau_rise : volt   # Spike trace\n",
    "dY/dt = -Y / tau_decay : volt  # Glutamate decay\n",
    "w : siemens  # Synaptic weight (conductance)\n",
    "I_post = w * X : amp (summed)\n",
    "'''\n",
    "# Isyn_exc = w * X * (v_post - EL) : amp \n",
    "syn_eqs_inh = '''\n",
    "dX/dt = -X / tau_decay + Y / tau_rise : volt  # Spike trace\n",
    "dY/dt = -Y / tau_decay : volt  # Glutamate decay\n",
    "w : siemens  # Synaptic weight (conductance)\n",
    "I_post = w * X : amp (summed)\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4cda873-deff-49bb-87b2-c6f1a89fea8f",
   "metadata": {
    "id": "e4cda873-deff-49bb-87b2-c6f1a89fea8f"
   },
   "outputs": [],
   "source": [
    "# dims = [784,400,225,64]\n",
    "dims = [50,40,30,20]\n",
    "\n",
    "gist_dim = 16\n",
    "\n",
    "\n",
    "\n",
    "def make_groups(dims, eqs = eqs):\n",
    "\n",
    "  groups = []\n",
    "\n",
    "  for dim in dims:\n",
    "\n",
    "     groups.append(NeuronGroup(dim, eqs, threshold='v > Vcut', reset='v = Vr', method='euler'))\n",
    "\n",
    "  for group in groups:\n",
    "     group.v = EL\n",
    "\n",
    "\n",
    "  return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1632fe95-ea62-4a1c-b39d-200e31caea12",
   "metadata": {
    "id": "1632fe95-ea62-4a1c-b39d-200e31caea12"
   },
   "outputs": [],
   "source": [
    "def make_bottom_up_connections(Rs, Es_0, Es_1, syn_eqs_exc, syn_eqs_inh):\n",
    "\n",
    "\n",
    "  S_p = Synapses(Rs, Es_0, model=syn_eqs_exc,\n",
    "        on_pre='Y = 1')\n",
    "  S_p.connect(condition='i == j')  # One-to-one connections\n",
    "  S_p.w = 'w_init'\n",
    "\n",
    "\n",
    "  S_m = Synapses(Rs, Es_1, model=syn_eqs_inh,\n",
    "        on_pre='Y = 1*volt')\n",
    "  S_m.connect(condition='i == j')  # One-to-one connections\n",
    "  S_m.w = 'w_init'\n",
    "\n",
    "  return S_p, S_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lgB5lkb8fdCc",
   "metadata": {
    "id": "lgB5lkb8fdCc"
   },
   "outputs": [],
   "source": [
    "def make_top_down_connections(Rs, Es_0, Es_1, syn_eqs_exc, syn_eqs_inh):\n",
    "\n",
    "\n",
    "  S_p = Synapses(Rs, Es_1, model=syn_eqs_exc,\n",
    "        on_pre='Y = 1*volt')\n",
    "  S_p.connect()\n",
    "  S_p.w = 'rand() * w_init'\n",
    "\n",
    "\n",
    "  S_m = Synapses(Rs, Es_0, model=syn_eqs_inh,\n",
    "        on_pre='Y = 1*volt')\n",
    "  S_m.connect()\n",
    "  S_m.w = 'rand() * w_init'\n",
    "\n",
    "\n",
    "  return S_p, S_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ZBCZOcD97VdQ",
   "metadata": {
    "id": "ZBCZOcD97VdQ"
   },
   "outputs": [],
   "source": [
    "def make_gist_connections(Rs, G):\n",
    "\n",
    "  S = Synapses(Rs[0], G, model=syn_eqs_exc,\n",
    "        on_pre='Y = 1*volt')\n",
    "  S.connect(p=0.05)  # Connect with 5% probability\n",
    "  S.w = 'rand() * w_init'   # This is slightly different from the paper: it should be based on a ratio\n",
    "\n",
    "  S_gist_input = S\n",
    "\n",
    "  for R in Rs[1:]:\n",
    "    S = Synapses(G, R, model=syn_eqs_exc,\n",
    "        on_pre='Y = 1*volt')\n",
    "    S.connect(p=0.05)  # Connect with 5% probability\n",
    "    S_gist_output = S\n",
    "\n",
    "  return S_gist_input, S_gist_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "yKTMede3Unyd",
   "metadata": {
    "id": "yKTMede3Unyd"
   },
   "outputs": [],
   "source": [
    "# num_classes_per_layer and max_depth depend on the same parameters used when generating the datset\n",
    "\n",
    "def make_output_layer(num_classes_per_layer, max_depth, w_out_init = None ):\n",
    "\n",
    "    if w_out_init == None:\n",
    "        w_out_init = w_init/10\n",
    "        \n",
    "        \n",
    "\n",
    "    total_neurons = sum([num_classes_per_layer**(d+1) for d in range(max_depth)])\n",
    "    \n",
    "    \n",
    "    Os = NeuronGroup(N=total_neurons, model = out_eqs, threshold='v > Vcut', reset='v = Vr', method='euler')\n",
    "\n",
    "    \n",
    "\n",
    "    S_o = Synapses(Os, Os, model=syn_eqs_exc, on_pre='Y = 1*volt')\n",
    "    \n",
    "    trace = 0\n",
    "    for d in range(num_classes_per_layer - 1):\n",
    "\n",
    "        new_trace = trace + num_classes_per_layer**(d+1)\n",
    "        \n",
    "        source_indices = list(range(trace, trace + num_classes_per_layer**(d+1)))\n",
    "        target_indices = list(range(new_trace , new_trace + num_classes_per_layer**(d+2)))\n",
    "\n",
    "        ii, jj = np.meshgrid(source_indices, target_indices, indexing='ij')\n",
    "        \n",
    "        S_o.connect(i=ii.flatten(), j=jj.flatten())\n",
    "\n",
    "        trace = new_trace\n",
    "\n",
    "\n",
    "    stimulus_indices = []\n",
    "\n",
    "    for i, n in enumerate([num_classes_per_layer**i for i in range(1, max_depth+1)]):\n",
    "        for _ in range(n):\n",
    "            stimulus_indices.append(int(i))\n",
    "            \n",
    "    Os.indices = stimulus_indices \n",
    "\n",
    "\n",
    "    return Os, S_o\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0HO2o7eGvf0C",
   "metadata": {
    "id": "0HO2o7eGvf0C"
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_network(dims, syn_eqs_exc, syn_eqs_inh, num_classes_per_layer, max_depth, w_out_init = None ):\n",
    "\n",
    "    max_depth += 1\n",
    "    \n",
    "    Rs = make_groups(dims)\n",
    "    Es_0 = make_groups(dims)\n",
    "    Es_1 = make_groups(dims)\n",
    "    G = NeuronGroup(gist_dim, eqs, threshold='v > Vcut', reset='v = Vr', method='euler')\n",
    "    \n",
    "    Os, S_o_internal = make_output_layer(num_classes_per_layer, max_depth) # Hopefully this is correct\n",
    "    \n",
    "    connections = {}\n",
    "    connections[\"output_internal\"] = S_o_internal\n",
    "    \n",
    "    for i in range(len(Rs)):\n",
    "    \n",
    "    \n",
    "        S_p, S_m = make_bottom_up_connections(Rs[i], Es_0[i], Es_1[i], syn_eqs_exc, syn_eqs_inh)\n",
    "        \n",
    "        connections[f\"bottom_up_{i}\"] = [S_p, S_m]\n",
    "    \n",
    "    if i != len(Rs)-1:\n",
    "    \n",
    "        S_p, S_m = make_top_down_connections(Rs[i+1], Es_0[i], Es_1[i], syn_eqs_exc, syn_eqs_inh)\n",
    "        \n",
    "        connections[f\"top_down_{i}\"] = [S_p, S_m]\n",
    "    \n",
    "    S_gist_input, S_gist_output = make_gist_connections(Rs, G)\n",
    "    \n",
    "    connections[\"gist_input\"] = S_gist_input\n",
    "    connections[\"gist_output\"] = S_gist_output\n",
    "    \n",
    "    '''\n",
    "    S_o_external = Synapses(Rs[-1], Os, model=syn_eqs_exc,\n",
    "        on_pre='Y = 1*volt')\n",
    "    S_o_external.connect()\n",
    "    S_o_external.w = 'rand() * w_init'\n",
    "    '''\n",
    "    S_o_external = []\n",
    "    for O in Os:\n",
    "        S = Synapses(Rs[-1], O, model=syn_eqs_exc, on_pre='Y = 1*volt')\n",
    "        S.connect()\n",
    "        S.w = 'rand() * w_init'\n",
    "        S_o_external.append(S)\n",
    "    connections[\"output_external\"] = S_o_external\n",
    "\n",
    "\n",
    "    return Rs, Es_0, Es_1, G, Os, connections\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fab0d6-5862-442a-8f30-a43f29742762",
   "metadata": {},
   "source": [
    "# Helpful for setting up input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef16053a-1a23-4a21-9099-2f384c0d0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tensor(tensor, old_min, old_max, new_min, new_max):\n",
    "\n",
    "    normalized_tensor = (tensor - old_min) / (old_max - old_min)\n",
    "\n",
    "\n",
    "    scaled_tensor = normalized_tensor * (new_max - new_min) + new_min\n",
    "\n",
    "    return scaled_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22cb22e1-5d5b-42fc-892a-93277adcfe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_unwrap_dataset(dt, minval,maxval):\n",
    "\n",
    "\n",
    "    minimum = 0\n",
    "    maximum = 0\n",
    "    \n",
    "    all_curves = [torch.tensor(curve, dtype = torch.float64) for curve in chain.from_iterable(dt[\"curves\"].values())]\n",
    "    \n",
    "    for curve in all_curves:\n",
    "    \n",
    "        _min = torch.min(curve)\n",
    "        _max = torch.max(curve)\n",
    "        if(minimum > _min): minimum = _min\n",
    "        if(maximum < _max): maximum = _max\n",
    "\n",
    "\n",
    "    unwrapped = []\n",
    "    for key in dt[\"categories\"].keys():\n",
    "        for curve in dt[\"curves\"][key]:\n",
    "            unwrapped.append((torch.tensor(key), normalize_tensor(torch.tensor(curve), minimum, maximum, minval, maxval)))\n",
    "            \n",
    "    return unwrapped\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7899bab7-8b66-496f-80a3-89e3490c3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_stimuli_indexes_from_labels(labels, num_classes_per_layer):\n",
    "\n",
    "    if labels.ndim == 1:\n",
    "        labels = labels.unsqueeze(0)  # Convert to 2D with shape (1, len(I_indexes))\n",
    "\n",
    "    indexes = torch.zeros_like(labels)\n",
    "    \n",
    "    for i in range(0, labels.shape[1]):\n",
    "    \n",
    "        summed = 0\n",
    "        if i>0:\n",
    "            summed = torch.stack([labels[:,j]*num_classes_per_layer**(i-j) for j in range(i)]).sum(dim=0)\n",
    "    \n",
    "        indexes[:,i] = summed + labels[:,i] # These are more intelligible, since they indicate which neuron to stimulate for each level of granularity\n",
    "\n",
    "    # But we need to adapt them for a situation where all neurons are concatenated in a single list\n",
    "    \n",
    "    to_sum = 0\n",
    "    for i in range(0, labels.shape[1]):\n",
    "\n",
    "        if i>0:\n",
    "            to_sum += num_classes_per_layer**i \n",
    "\n",
    "        indexes[:,i] = indexes[:,i] + to_sum\n",
    "\n",
    "    return indexes\n",
    "\n",
    "\n",
    "\n",
    "def get_output_current_arrays(I_indexes, dim, I_value):\n",
    "    # Ensure I_indexes is 2D for consistent processing\n",
    "    if I_indexes.ndim == 1:\n",
    "        I_indexes = I_indexes.unsqueeze(0)  # Convert to 2D with shape (1, len(I_indexes))\n",
    "\n",
    "    # Create an output tensor of zeros\n",
    "    out = torch.zeros((I_indexes.shape[0], dim), dtype=torch.float32)\n",
    "\n",
    "    # Row indices (batch indices) for advanced indexing\n",
    "    row_indices = torch.arange(I_indexes.shape[0]).repeat_interleave(I_indexes.shape[1])\n",
    "\n",
    "    # Flattened column indices (curve indexes)\n",
    "    col_indices = I_indexes.flatten()\n",
    "\n",
    "    # Set the values using advanced indexing\n",
    "    out[row_indices, col_indices] = I_value\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class CurveDataset(Dataset):\n",
    "    def __init__(self, data, minval, maxval):\n",
    "        \n",
    "        self.data = normalize_and_unwrap_dataset(data, minval, maxval)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        labels, curves = self.data[idx]\n",
    "      \n",
    "  \n",
    "        return labels, curves.flatten()\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn(batch, msec_step, num_pause_blocks, num_classes_per_layer, out_dim):\n",
    "\n",
    "    \n",
    "\n",
    "    labels, curves = zip(*batch)\n",
    "\n",
    "    labels = torch.stack(labels, dim=0)\n",
    "    curves = torch.stack(curves, dim=0)\n",
    "\n",
    "\n",
    "   \n",
    "    pause = torch.zeros_like(curves[0])  \n",
    "    \n",
    "    pause_block = torch.tile(pause, (num_pause_blocks, 1))  \n",
    "    \n",
    "    # Interleave stimulus rows with the pause block\n",
    "    curves_with_pause = torch.vstack([torch.vstack((row, pause_block)) for row in curves])\n",
    "\n",
    "    visual_stimulus = TimedArray(curves_with_pause.numpy() * nA, dt=msec_step*ms)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    out_stimuli_idx = get_output_stimuli_indexes_from_labels(labels, num_classes_per_layer)\n",
    "   \n",
    "    out_stimuli_array = get_output_current_arrays(out_stimuli_idx, out_dim, 1)\n",
    "\n",
    "    label_pause = torch.zeros(out_dim)  \n",
    "    \n",
    "    label_pause_block = torch.tile(label_pause, (num_pause_blocks, 1)) \n",
    "\n",
    "    out_stimuli_with_pause = torch.vstack([torch.vstack((row, label_pause_block)) for row in out_stimuli_array])\n",
    "\n",
    "    output_stimuli = TimedArray(out_stimuli_with_pause.numpy() * nA, dt=msec_step*ms) \n",
    "    \n",
    "\n",
    "    return output_stimuli , visual_stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac4d286-c534-47b9-a39f-2ddf03581a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00477b05-4925-44dc-bf39-04b4b7cc1819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce057cf3-0c48-460e-b499-cf6b31e37f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16871412-6ac8-4121-886b-8e605ba8bc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fa69c0b-f02f-4d63-b488-40bc7758c46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO       The synaptic equation for the variable X does not specify whether it should be integrated at every timestep ('clock-driven') or only at spiking events ('event-driven'). It will be integrated at every timestep which can slow down your simulation unnecessarily if you only need the values of this variable whenever a spike occurs. Specify the equation as clock-driven explicitly to avoid this warning. [brian2.synapses.synapses.clock_driven]\n",
      "INFO       The synaptic equation for the variable Y does not specify whether it should be integrated at every timestep ('clock-driven') or only at spiking events ('event-driven'). It will be integrated at every timestep which can slow down your simulation unnecessarily if you only need the values of this variable whenever a spike occurs. Specify the equation as clock-driven explicitly to avoid this warning. [brian2.synapses.synapses.clock_driven]\n",
      "cl : warning della riga di comando D9025 : override di '/W3' con '/w'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 14.0\\\\VC\\\\BIN\\\\x86_amd64\\\\link.exe' failed with exit code 1158 (LinkError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_cython_magic_32a1cdc0f6fb3e035c7e07036edf98c2.cpp\n",
      "_cython_magic_32a1cdc0f6fb3e035c7e07036edf98c2.obj : warning LNK4197: esportazione 'PyInit__cython_magic_32a1cdc0f6fb3e035c7e07036edf98c2' specificata più volte; verrà utilizzata la prima specifica\n",
      "   Creazione della libreria C:\\Users\\bruno\\.cython\\brian_extensions\\Users\\bruno\\.cython\\brian_extensions\\_cython_magic_32a1cdc0f6fb3e035c7e07036edf98c2.cp311-win_amd64.lib e dell'oggetto C:\\Users\\bruno\\.cython\\brian_extensions\\Users\\bruno\\.cython\\brian_extensions\\_cython_magic_32a1cdc0f6fb3e035c7e07036edf98c2.cp311-win_amd64.exp\n",
      "Generazione codice in corso...\n",
      "Generazione codice terminata\n",
      "LINK : fatal error LNK1158: impossibile eseguire 'rc.exe'\n"
     ]
    }
   ],
   "source": [
    "dims = [15**2, 50,40,30]\n",
    "Rs, Es_0, Es_1, G, Os, connections = make_network(dims, syn_eqs_exc, syn_eqs_inh, num_classes_per_layer=3, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26e07d4a-7015-4980-824b-6c82bfaef728",
   "metadata": {},
   "outputs": [],
   "source": [
    "su = Synthetic_Dataset_Utils()\n",
    "\n",
    "ranges = [30,30,30,30]  # Ranges for each parameter\n",
    "\n",
    "prior_params = [10,10,10,10]  # Initial parameters\n",
    "\n",
    "num_samples_per_class=5\n",
    "N=15\n",
    "\n",
    "# Build the tree\n",
    "max_depth = 3 # Adjust as needed\n",
    "num_classes_per_layer = 3  # Adjust as needed\n",
    "\n",
    "std_multiplier = 1\n",
    "\n",
    "tree = su.build_tree(prior_params, 0, max_depth, num_classes_per_layer, std_multiplier, ranges)\n",
    "\n",
    "synth_dataset = su.make_dataset(tree, num_samples_per_class=num_samples_per_class, N=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a4fa470-20a2-424b-b831-eae2887e6576",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = sum([len(o) for o in Os])\n",
    "\n",
    "\n",
    "batch_size = 20\n",
    "num_pause_blocks = 1\n",
    "\n",
    "dataset = CurveDataset(synth_dataset, 0.6, 1.5)\n",
    "dl = DataLoader( dataset, shuffle = True, batch_size = batch_size, collate_fn = partial(collate_fn, msec_step=100, num_pause_blocks=num_pause_blocks,\n",
    "                                                                                num_classes_per_layer = num_classes_per_layer, out_dim = output_dim) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88ace3fd-57b0-4fbd-8f3e-e8c741a6c1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for output_stimuli, input_stimuli in dl:\n",
    "\n",
    "    run((batch_size + batch_size*num_pause_blocks)*100 * ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8aeb5b-5d70-457f-9621-62b913b47362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d5551-26cc-4093-88ac-28068d6dec9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d5d75e-9c75-4823-8fd5-e6ceb6efdc93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d25aa-542a-44af-bce2-b0951461ea00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef56e4e-8e40-4006-a4b5-11d4f48e1ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13749321-4b51-4edb-b20b-684dc1583c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190bc8e0-bed4-47a6-b368-af23264f6f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01710e9-8872-48fe-80f1-3c2ec7edd40a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zkD5Zs72axi9",
   "metadata": {
    "id": "zkD5Zs72axi9"
   },
   "outputs": [],
   "source": [
    "def training_phase_1(network, dl):\n",
    "\n",
    "  for label_input, curve_input in dl:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lOfMXzfIaxdn",
   "metadata": {
    "id": "lOfMXzfIaxdn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T9V1Ufi3axau",
   "metadata": {
    "id": "T9V1Ufi3axau"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jJZrHvJVaxXE",
   "metadata": {
    "id": "jJZrHvJVaxXE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ee7d2-a787-41b0-a184-154cbb8d3242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f51cc-b549-4b0c-83f2-eb6df4bfaf66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2226e1-6834-4dff-82e4-59e522ee9a81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99fb598-329c-41f4-8998-97d02000a5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719d563b-4185-43e6-b26a-41ae6cfdd1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "586f1b19-bab1-4990-b2ca-1aabe4ae053c",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JUtGtvxAaxRO",
   "metadata": {
    "id": "JUtGtvxAaxRO"
   },
   "outputs": [],
   "source": [
    "eqs_neuron = '''\n",
    "dv/dt = (-gL * (v - EL) + gL * DeltaT * exp((v - Vth) / DeltaT) + I - A) / Cm : volt\n",
    "dA/dt = (c * (v - EL) - A) / tau_A : amp\n",
    "I = stimulus(t)  : amp  \n",
    "'''\n",
    "\n",
    "\n",
    "neuron = make_groups([1], eqs = eqs_neuron)[0]\n",
    "\n",
    "neuron\n",
    "\n",
    "# Change 2 to any value from 0.6 to 1.5, which is the range of current intensity we are probably going to use\n",
    "\n",
    "stimulus = TimedArray(np.hstack([[c] for c in np.ones(1)*0.8]) * nA, dt=10*ms)\n",
    "\n",
    "\n",
    "\n",
    "neuron.v = EL\n",
    "neuron.A = 0 * nA\n",
    "\n",
    "# Monitor the specific neuron (neuron 2)\n",
    "monitor = StateMonitor(neuron, ['v', 'I'], record=[0])\n",
    "spike_monitor = SpikeMonitor(neuron)\n",
    "\n",
    "run(1 * second)\n",
    "\n",
    "# Plot membrane potential\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Membrane potential plot\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(monitor.t / ms, monitor.v[0] / mV, label='Neuron 2 Membrane Potential')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Membrane Potential (mV)')\n",
    "plt.title('Stimulus Applied to Single Neuron')\n",
    "plt.legend()\n",
    "\n",
    "# Firing rate plot\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.hist(spike_monitor.t / ms, bins=10, alpha=0.7)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Spike Count')\n",
    "plt.title('Firing Rate of Neuron 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "0.6: 0\n",
    "0.625: 0\n",
    "0.63: 0.5\n",
    "0.65: 1.5\n",
    "0.7: 2.8\n",
    "0.8: 4.5\n",
    "1: 7.5\n",
    "1.5: 14\n",
    "2: 20\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f18219-77eb-4144-8b49-d2df646ad21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's connect 2 groups as a trial\n",
    "\n",
    "G1 = NeuronGroup(5, 'v : volt', threshold='v > Vcut', reset='v = Vr', method='euler')  # Presynaptic neurons\n",
    "G2 = NeuronGroup(5, eqs, threshold='v > Vcut', reset='v = Vr; A += b', method='euler')  # Postsynaptic neurons\n",
    "\n",
    "# Initialize variables\n",
    "G1.v = EL\n",
    "G2.v = EL\n",
    "G2.A = 0 * nA\n",
    "\n",
    "# Create synapses\n",
    "S = Synapses(G1, G2, model=syn_eqs_exc,\n",
    "             on_pre='Y = 1*volt', method = \"euler\")  # Increment glutamate release on spike\n",
    "S.connect(p=0.1)  # Random connections\n",
    "S.w = 'rand() * w_init'  # Random initial weights\n",
    "\n",
    "# Monitors\n",
    "spike_mon_G1 = SpikeMonitor(G1)\n",
    "spike_mon_G2 = SpikeMonitor(G2)\n",
    "state_mon_G2 = StateMonitor(G2, ['v', 'I', 'A'], record=True)\n",
    "\n",
    "# Run simulation\n",
    "b2.run(500 * ms)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot membrane potential of a postsynaptic neuron\n",
    "plt.subplot(311)\n",
    "plt.plot(state_mon_G2.t / ms, state_mon_G2.v[0] / mV, label='Membrane potential (v)')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Voltage (mV)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "neural_computation_kernel",
   "language": "python",
   "name": "neural_computation_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
